diff --git a/api/video/video_codec_type.h b/api/video/video_codec_type.h
index 12dcfac1b9..fdbc5187d8 100644
--- a/api/video/video_codec_type.h
+++ b/api/video/video_codec_type.h
@@ -22,6 +22,7 @@ enum VideoCodecType {
   kVideoCodecVP9,
   kVideoCodecAV1,
   kVideoCodecH264,
+  kVideoCodecH265,
   kVideoCodecMultiplex,
 };
 
diff --git a/api/video_codecs/video_codec.cc b/api/video_codecs/video_codec.cc
index 490eced4e0..a06e89a820 100644
--- a/api/video_codecs/video_codec.cc
+++ b/api/video_codecs/video_codec.cc
@@ -25,6 +25,7 @@ constexpr char kPayloadNameVp9[] = "VP9";
 // frozen.
 constexpr char kPayloadNameAv1[] = "AV1X";
 constexpr char kPayloadNameH264[] = "H264";
+constexpr char kPayloadNameH265[] = "H265";
 constexpr char kPayloadNameGeneric[] = "Generic";
 constexpr char kPayloadNameMultiplex[] = "Multiplex";
 }  // namespace
@@ -56,6 +57,15 @@ bool VideoCodecH264::operator==(const VideoCodecH264& other) const {
           numberOfTemporalLayers == other.numberOfTemporalLayers);
 }
 
+bool VideoCodecH265::operator==(const VideoCodecH265& other) const {
+  return (frameDroppingOn == other.frameDroppingOn &&
+          keyFrameInterval == other.keyFrameInterval &&
+          vpsLen == other.vpsLen && spsLen == other.spsLen &&
+          ppsLen == other.ppsLen &&
+          (spsLen == 0 || memcmp(spsData, other.spsData, spsLen) == 0) &&
+          (ppsLen == 0 || memcmp(ppsData, other.ppsData, ppsLen) == 0));
+}
+
 VideoCodec::VideoCodec()
     : codecType(kVideoCodecGeneric),
       width(0),
@@ -105,6 +115,16 @@ const VideoCodecH264& VideoCodec::H264() const {
   return codec_specific_.H264;
 }
 
+VideoCodecH265* VideoCodec::H265() {
+  RTC_DCHECK_EQ(codecType, kVideoCodecH265);
+  return &codec_specific_.H265;
+}
+
+const VideoCodecH265& VideoCodec::H265() const {
+  RTC_DCHECK_EQ(codecType, kVideoCodecH265);
+  return codec_specific_.H265;
+}
+
 const char* CodecTypeToPayloadString(VideoCodecType type) {
   switch (type) {
     case kVideoCodecVP8:
@@ -115,6 +135,8 @@ const char* CodecTypeToPayloadString(VideoCodecType type) {
       return kPayloadNameAv1;
     case kVideoCodecH264:
       return kPayloadNameH264;
+    case kVideoCodecH265:
+     return kPayloadNameH265;
     case kVideoCodecMultiplex:
       return kPayloadNameMultiplex;
     case kVideoCodecGeneric:
@@ -131,6 +153,8 @@ VideoCodecType PayloadStringToCodecType(const std::string& name) {
     return kVideoCodecAV1;
   if (absl::EqualsIgnoreCase(name, kPayloadNameH264))
     return kVideoCodecH264;
+  if (absl::EqualsIgnoreCase(name, kPayloadNameH265))
+    return kVideoCodecH265;
   if (absl::EqualsIgnoreCase(name, kPayloadNameMultiplex))
     return kVideoCodecMultiplex;
   return kVideoCodecGeneric;
diff --git a/api/video_codecs/video_codec.h b/api/video_codecs/video_codec.h
index 48e72edb67..a9ae544245 100644
--- a/api/video_codecs/video_codec.h
+++ b/api/video_codecs/video_codec.h
@@ -84,6 +84,21 @@ struct VideoCodecH264 {
   uint8_t numberOfTemporalLayers;
 };
 
+struct VideoCodecH265 {
+  bool operator==(const VideoCodecH265& other) const;
+  bool operator!=(const VideoCodecH265& other) const {
+    return !(*this == other);
+  }
+  bool frameDroppingOn;
+  int keyFrameInterval;
+  const uint8_t* vpsData;
+  size_t vpsLen;
+  const uint8_t* spsData;
+  size_t spsLen;
+  const uint8_t* ppsData;
+  size_t ppsLen;
+};
+
 // Translates from name of codec to codec type and vice versa.
 RTC_EXPORT const char* CodecTypeToPayloadString(VideoCodecType type);
 RTC_EXPORT VideoCodecType PayloadStringToCodecType(const std::string& name);
@@ -92,6 +107,7 @@ union VideoCodecUnion {
   VideoCodecVP8 VP8;
   VideoCodecVP9 VP9;
   VideoCodecH264 H264;
+  VideoCodecH265 H265;
 };
 
 enum class VideoCodecMode { kRealtimeVideo, kScreensharing };
@@ -161,6 +177,8 @@ class RTC_EXPORT VideoCodec {
   const VideoCodecVP9& VP9() const;
   VideoCodecH264* H264();
   const VideoCodecH264& H264() const;
+  VideoCodecH265* H265();
+  const VideoCodecH265& H265() const;
 
  private:
   // TODO(hta): Consider replacing the union with a pointer type.
diff --git a/api/video_codecs/video_decoder_software_fallback_wrapper.cc b/api/video_codecs/video_decoder_software_fallback_wrapper.cc
index 128087f207..81a56cfd79 100644
--- a/api/video_codecs/video_decoder_software_fallback_wrapper.cc
+++ b/api/video_codecs/video_decoder_software_fallback_wrapper.cc
@@ -181,6 +181,10 @@ void VideoDecoderSoftwareFallbackWrapper::UpdateFallbackDecoderHistograms() {
       RTC_HISTOGRAM_COUNTS_100000(kFallbackHistogramsUmaPrefix + "H264",
                                   hw_decoded_frames_since_last_fallback_);
       break;
+    case kVideoCodecH265:
+      RTC_HISTOGRAM_COUNTS_100000(kFallbackHistogramsUmaPrefix + "H265",
+                                  hw_decoded_frames_since_last_fallback_);
+      break;
     case kVideoCodecMultiplex:
       RTC_HISTOGRAM_COUNTS_100000(kFallbackHistogramsUmaPrefix + "Multiplex",
                                   hw_decoded_frames_since_last_fallback_);
diff --git a/api/video_codecs/video_encoder.cc b/api/video_codecs/video_encoder.cc
index da22746493..dd385e100f 100644
--- a/api/video_codecs/video_encoder.cc
+++ b/api/video_codecs/video_encoder.cc
@@ -60,6 +60,21 @@ VideoCodecH264 VideoEncoder::GetDefaultH264Settings() {
   return h264_settings;
 }
 
+VideoCodecH265 VideoEncoder::GetDefaultH265Settings() {
+  VideoCodecH265 h265_settings;
+  memset(&h265_settings, 0, sizeof(h265_settings));
+
+  // h265_settings.profile = kProfileBase;
+  h265_settings.frameDroppingOn = true;
+  h265_settings.keyFrameInterval = 3000;
+  h265_settings.spsData = nullptr;
+  h265_settings.spsLen = 0;
+  h265_settings.ppsData = nullptr;
+  h265_settings.ppsLen = 0;
+  
+  return h265_settings;
+}
+
 VideoEncoder::ScalingSettings::ScalingSettings() = default;
 
 VideoEncoder::ScalingSettings::ScalingSettings(KOff) : ScalingSettings() {}
diff --git a/api/video_codecs/video_encoder.h b/api/video_codecs/video_encoder.h
index d73c9f0dcb..c759eeea40 100644
--- a/api/video_codecs/video_encoder.h
+++ b/api/video_codecs/video_encoder.h
@@ -327,6 +327,7 @@ class RTC_EXPORT VideoEncoder {
   static VideoCodecVP8 GetDefaultVp8Settings();
   static VideoCodecVP9 GetDefaultVp9Settings();
   static VideoCodecH264 GetDefaultH264Settings();
+  static VideoCodecH265 GetDefaultH265Settings();
 
   virtual ~VideoEncoder() {}
 
diff --git a/api/video_codecs/video_encoder_config.cc b/api/video_codecs/video_encoder_config.cc
index 5956d60365..e7a14f7ce3 100644
--- a/api/video_codecs/video_encoder_config.cc
+++ b/api/video_codecs/video_encoder_config.cc
@@ -95,6 +95,8 @@ void VideoEncoderConfig::EncoderSpecificSettings::FillEncoderSpecificSettings(
     FillVideoCodecVp8(codec->VP8());
   } else if (codec->codecType == kVideoCodecVP9) {
     FillVideoCodecVp9(codec->VP9());
+  } else if (codec->codecType == kVideoCodecH265) {
+    FillVideoCodecH265(codec->H265());
   } else {
     RTC_NOTREACHED() << "Encoder specifics set/used for unknown codec type.";
   }
@@ -105,6 +107,11 @@ void VideoEncoderConfig::EncoderSpecificSettings::FillVideoCodecH264(
   RTC_NOTREACHED();
 }
 
+void VideoEncoderConfig::EncoderSpecificSettings::FillVideoCodecH265(
+    VideoCodecH265* h265_settings) const {
+  RTC_NOTREACHED();
+}
+
 void VideoEncoderConfig::EncoderSpecificSettings::FillVideoCodecVp8(
     VideoCodecVP8* vp8_settings) const {
   RTC_NOTREACHED();
@@ -124,6 +131,15 @@ void VideoEncoderConfig::H264EncoderSpecificSettings::FillVideoCodecH264(
   *h264_settings = specifics_;
 }
 
+VideoEncoderConfig::H265EncoderSpecificSettings::H265EncoderSpecificSettings(
+    const VideoCodecH265& specifics)
+    : specifics_(specifics) {}
+
+void VideoEncoderConfig::H265EncoderSpecificSettings::FillVideoCodecH265(
+    VideoCodecH265* h265_settings) const {
+  *h265_settings = specifics_;
+}
+
 VideoEncoderConfig::Vp8EncoderSpecificSettings::Vp8EncoderSpecificSettings(
     const VideoCodecVP8& specifics)
     : specifics_(specifics) {}
diff --git a/api/video_codecs/video_encoder_config.h b/api/video_codecs/video_encoder_config.h
index 7a59dacd1b..f98359b782 100644
--- a/api/video_codecs/video_encoder_config.h
+++ b/api/video_codecs/video_encoder_config.h
@@ -84,6 +84,7 @@ class VideoEncoderConfig {
     virtual void FillVideoCodecVp8(VideoCodecVP8* vp8_settings) const;
     virtual void FillVideoCodecVp9(VideoCodecVP9* vp9_settings) const;
     virtual void FillVideoCodecH264(VideoCodecH264* h264_settings) const;
+    virtual void FillVideoCodecH265(VideoCodecH265* h265_settings) const;
 
    private:
     ~EncoderSpecificSettings() override {}
@@ -99,6 +100,15 @@ class VideoEncoderConfig {
     VideoCodecH264 specifics_;
   };
 
+  class H265EncoderSpecificSettings : public EncoderSpecificSettings {
+   public:
+    explicit H265EncoderSpecificSettings(const VideoCodecH265& specifics);
+    void FillVideoCodecH265(VideoCodecH265* h265_settings) const override;
+  
+   private:
+    VideoCodecH265 specifics_;
+  };
+
   class Vp8EncoderSpecificSettings : public EncoderSpecificSettings {
    public:
     explicit Vp8EncoderSpecificSettings(const VideoCodecVP8& specifics);
diff --git a/call/rtp_payload_params.cc b/call/rtp_payload_params.cc
index ad979a590a..6c27c9775f 100644
--- a/call/rtp_payload_params.cc
+++ b/call/rtp_payload_params.cc
@@ -95,6 +95,12 @@ void PopulateRtpWithCodecSpecifics(const CodecSpecificInfo& info,
       rtp->simulcastIdx = spatial_index.value_or(0);
       return;
     }
+    case kVideoCodecH265: {
+      auto h265_header = rtp->video_type_header.emplace<RTPVideoHeaderH265>();
+      h265_header.packetization_mode =
+          info.codecSpecific.H265.packetization_mode;
+      return;
+    }
     case kVideoCodecMultiplex:
     case kVideoCodecGeneric:
       rtp->codec = kVideoCodecGeneric;
@@ -286,6 +292,7 @@ void RtpPayloadParams::SetGeneric(const CodecSpecificInfo* codec_specific_info,
                       is_keyframe, rtp_video_header);
       }
       return;
+    case VideoCodecType::kVideoCodecH265:
     case VideoCodecType::kVideoCodecMultiplex:
       return;
   }
diff --git a/common_video/BUILD.gn b/common_video/BUILD.gn
index 9cb6f454d7..ffba448d0d 100644
--- a/common_video/BUILD.gn
+++ b/common_video/BUILD.gn
@@ -40,6 +40,17 @@ rtc_library("common_video") {
     "video_render_frames.h",
   ]
 
+  sources += [
+    "h265/h265_common.cc",
+    "h265/h265_common.h",
+    "h265/h265_pps_parser.cc",
+    "h265/h265_pps_parser.h",
+    "h265/h265_sps_parser.cc",
+    "h265/h265_sps_parser.h",
+    "h265/h265_vps_parser.cc",
+    "h265/h265_vps_parser.h",
+  ]
+
   deps = [
     "../api:scoped_refptr",
     "../api/task_queue",
diff --git a/common_video/h265/h265_common.cc b/common_video/h265/h265_common.cc
new file mode 100644
index 0000000000..5c98ea1dfb
--- /dev/null
+++ b/common_video/h265/h265_common.cc
@@ -0,0 +1,110 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "common_video/h265/h265_common.h"
+
+namespace webrtc {
+namespace H265 {
+
+const uint8_t kNaluTypeMask = 0x7E;
+
+std::vector<NaluIndex> FindNaluIndices(const uint8_t* buffer,
+                                       size_t buffer_size) {
+  // This is sorta like Boyer-Moore, but with only the first optimization step:
+  // given a 3-byte sequence we're looking at, if the 3rd byte isn't 1 or 0,
+  // skip ahead to the next 3-byte sequence. 0s and 1s are relatively rare, so
+  // this will skip the majority of reads/checks.
+  std::vector<NaluIndex> sequences;
+  if (buffer_size < kNaluShortStartSequenceSize)
+    return sequences;
+
+  const size_t end = buffer_size - kNaluShortStartSequenceSize;
+  for (size_t i = 0; i < end;) {
+    if (buffer[i + 2] > 1) {
+      i += 3;
+    } else if (buffer[i + 2] == 1 && buffer[i + 1] == 0 && buffer[i] == 0) {
+      // We found a start sequence, now check if it was a 3 of 4 byte one.
+      NaluIndex index = {i, i + 3, 0};
+      if (index.start_offset > 0 && buffer[index.start_offset - 1] == 0)
+        --index.start_offset;
+
+      // Update length of previous entry.
+      auto it = sequences.rbegin();
+      if (it != sequences.rend())
+        it->payload_size = index.start_offset - it->payload_start_offset;
+
+      sequences.push_back(index);
+
+      i += 3;
+    } else {
+      ++i;
+    }
+  }
+
+  // Update length of last entry, if any.
+  auto it = sequences.rbegin();
+  if (it != sequences.rend())
+    it->payload_size = buffer_size - it->payload_start_offset;
+
+  return sequences;
+}
+
+NaluType ParseNaluType(uint8_t data) {
+  return static_cast<NaluType>((data & kNaluTypeMask) >> 1);
+}
+
+std::vector<uint8_t> ParseRbsp(const uint8_t* data, size_t length) {
+  std::vector<uint8_t> out;
+  out.reserve(length);
+
+  for (size_t i = 0; i < length;) {
+    // Be careful about over/underflow here. byte_length_ - 3 can underflow, and
+    // i + 3 can overflow, but byte_length_ - i can't, because i < byte_length_
+    // above, and that expression will produce the number of bytes left in
+    // the stream including the byte at i.
+    if (length - i >= 3 && !data[i] && !data[i + 1] && data[i + 2] == 3) {
+      // Two rbsp bytes.
+      out.push_back(data[i++]);
+      out.push_back(data[i++]);
+      // Skip the emulation byte.
+      i++;
+    } else {
+      // Single rbsp byte.
+      out.push_back(data[i++]);
+    }
+  }
+  return out;
+}
+
+void WriteRbsp(const uint8_t* bytes, size_t length, rtc::Buffer* destination) {
+  static const uint8_t kZerosInStartSequence = 2;
+  static const uint8_t kEmulationByte = 0x03u;
+  size_t num_consecutive_zeros = 0;
+  destination->EnsureCapacity(destination->size() + length);
+
+  for (size_t i = 0; i < length; ++i) {
+    uint8_t byte = bytes[i];
+    if (byte <= kEmulationByte &&
+        num_consecutive_zeros >= kZerosInStartSequence) {
+      // Need to escape.
+      destination->AppendData(kEmulationByte);
+      num_consecutive_zeros = 0;
+    }
+    destination->AppendData(byte);
+    if (byte == 0) {
+      ++num_consecutive_zeros;
+    } else {
+      num_consecutive_zeros = 0;
+    }
+  }
+}
+
+}  // namespace H265
+}  // namespace webrtc
\ No newline at end of file
diff --git a/common_video/h265/h265_common.h b/common_video/h265/h265_common.h
new file mode 100644
index 0000000000..8e36f962b4
--- /dev/null
+++ b/common_video/h265/h265_common.h
@@ -0,0 +1,100 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_VIDEO_H265_H265_COMMON_H_
+#define COMMON_VIDEO_H265_H265_COMMON_H_
+
+#include <memory>
+#include <vector>
+
+#include "rtc_base/buffer.h"
+
+namespace webrtc {
+
+namespace H265 {
+// The size of a full NALU start sequence {0 0 0 1}, used for the first NALU
+// of an access unit, and for SPS and PPS blocks.
+const size_t kNaluLongStartSequenceSize = 4;
+
+// The size of a shortened NALU start sequence {0 0 1}, that may be used if
+// not the first NALU of an access unit or an SPS or PPS block.
+const size_t kNaluShortStartSequenceSize = 3;
+
+// The size of the NALU type byte (1).
+const size_t kNaluTypeSize = 1;
+
+enum NaluType : uint8_t {
+  kTrailN = 0,
+  kTrailR = 1,
+  kTsaN = 2,
+  kTsaR = 3,
+  kStsaN = 4,
+  kStsaR = 5,
+  kRadlN = 6,
+  kRadlR = 7,
+  kBlaWLp = 16,
+  kBlaWRadl = 17,
+  kBlaNLp = 18,
+  kIdrWRadl = 19,
+  kIdrNLp = 20,
+  kCra = 21,
+  kRsvIrapVcl23 = 23,
+  kVps = 32,
+  kSps = 33,
+  kPps = 34,
+  kAud = 35,
+  kPrefixSei = 39,
+  kSuffixSei = 40,
+  kAP = 48,
+  kFU = 49
+};
+
+enum SliceType : uint8_t { kP = 0, kB = 1, kI = 2, kSp = 3, kSi = 4 };
+
+struct NaluIndex {
+  // Start index of NALU, including start sequence.
+  size_t start_offset;
+  // Start index of NALU payload, typically type header.
+  size_t payload_start_offset;
+  // Length of NALU payload, in bytes, counting from payload_start_offset.
+  size_t payload_size;
+};
+
+// Returns a vector of the NALU indices in the given buffer.
+std::vector<NaluIndex> FindNaluIndices(const uint8_t* buffer,
+                                       size_t buffer_size);
+
+// Get the NAL type from the header byte immediately following start sequence.
+NaluType ParseNaluType(uint8_t data);
+
+// Methods for parsing and writing RBSP. See section 7.4.2 of the H265 spec.
+//
+// The following sequences are illegal, and need to be escaped when encoding:
+// 00 00 00 -> 00 00 03 00
+// 00 00 01 -> 00 00 03 01
+// 00 00 02 -> 00 00 03 02
+// And things in the source that look like the emulation byte pattern (00 00 03)
+// need to have an extra emulation byte added, so it's removed when decoding:
+// 00 00 03 -> 00 00 03 03
+//
+// Decoding is simply a matter of finding any 00 00 03 sequence and removing
+// the 03 emulation byte.
+
+// Parse the given data and remove any emulation byte escaping.
+std::vector<uint8_t> ParseRbsp(const uint8_t* data, size_t length);
+
+// Write the given data to the destination buffer, inserting and emulation
+// bytes in order to escape any data the could be interpreted as a start
+// sequence.
+void WriteRbsp(const uint8_t* bytes, size_t length, rtc::Buffer* destination);
+}  // namespace H265
+}  // namespace webrtc
+
+#endif  // COMMON_VIDEO_H265_H265_COMMON_H_
\ No newline at end of file
diff --git a/common_video/h265/h265_pps_parser.cc b/common_video/h265/h265_pps_parser.cc
new file mode 100644
index 0000000000..f21decae07
--- /dev/null
+++ b/common_video/h265/h265_pps_parser.cc
@@ -0,0 +1,209 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "common_video/h265/h265_pps_parser.h"
+
+#include <memory>
+#include <vector>
+
+#include "common_video/h264/h264_common.h"
+#include "common_video/h265/h265_common.h"
+#include "rtc_base/bit_buffer.h"
+#include "rtc_base/logging.h"
+
+#define RETURN_EMPTY_ON_FAIL(x) \
+  if (!(x)) {                   \
+    return absl::nullopt;        \
+  }
+
+namespace {
+const int kMaxPicInitQpDeltaValue = 25;
+const int kMinPicInitQpDeltaValue = -26;
+}  // namespace
+
+namespace webrtc {
+
+// General note: this is based off the 02/2018 version of the H.265 standard.
+// You can find it on this page:
+// http://www.itu.int/rec/T-REC-H.265
+
+absl::optional<H265PpsParser::PpsState> H265PpsParser::ParsePps(
+    const uint8_t* data,
+    size_t length) {
+  // First, parse out rbsp, which is basically the source buffer minus emulation
+  // bytes (the last byte of a 0x00 0x00 0x03 sequence). RBSP is defined in
+  // section 7.3.1 of the H.264 standard.
+  std::vector<uint8_t> unpacked_buffer = H264::ParseRbsp(data, length);
+  rtc::BitBuffer bit_buffer(unpacked_buffer.data(), unpacked_buffer.size());
+  return ParseInternal(&bit_buffer);
+}
+
+bool H265PpsParser::ParsePpsIds(const uint8_t* data,
+                                size_t length,
+                                uint32_t* pps_id,
+                                uint32_t* sps_id) {
+  RTC_DCHECK(pps_id);
+  RTC_DCHECK(sps_id);
+  // First, parse out rbsp, which is basically the source buffer minus emulation
+  // bytes (the last byte of a 0x00 0x00 0x03 sequence). RBSP is defined in
+  // section 7.3.1 of the H.265 standard.
+  std::vector<uint8_t> unpacked_buffer = H264::ParseRbsp(data, length);
+  rtc::BitBuffer bit_buffer(unpacked_buffer.data(), unpacked_buffer.size());
+  return ParsePpsIdsInternal(&bit_buffer, pps_id, sps_id);
+}
+
+absl::optional<uint32_t> H265PpsParser::ParsePpsIdFromSliceSegmentLayerRbsp(
+    const uint8_t* data,
+    size_t length,
+    uint8_t nalu_type) {
+  rtc::BitBuffer slice_reader(data, length);
+
+  // first_slice_segment_in_pic_flag: u(1)
+  uint32_t first_slice_segment_in_pic_flag = 0;
+  RETURN_EMPTY_ON_FAIL(
+      slice_reader.ReadBits(&first_slice_segment_in_pic_flag, 1));
+
+  if (nalu_type >= H265::NaluType::kBlaWLp &&
+      nalu_type <= H265::NaluType::kRsvIrapVcl23) {
+    // no_output_of_prior_pics_flag: u(1)
+    RETURN_EMPTY_ON_FAIL(slice_reader.ConsumeBits(1));
+  }
+
+  // slice_pic_parameter_set_id: ue(v)
+  uint32_t slice_pic_parameter_set_id = 0;
+  if (!slice_reader.ReadExponentialGolomb(&slice_pic_parameter_set_id))
+    return absl::nullopt;
+
+  return slice_pic_parameter_set_id;
+}
+
+absl::optional<H265PpsParser::PpsState> H265PpsParser::ParseInternal(
+    rtc::BitBuffer* bit_buffer) {
+  PpsState pps;
+
+  RETURN_EMPTY_ON_FAIL(ParsePpsIdsInternal(bit_buffer, &pps.id, &pps.sps_id));
+
+  uint32_t bits_tmp;
+  uint32_t golomb_ignored;
+  // entropy_coding_mode_flag: u(1)
+  uint32_t entropy_coding_mode_flag;
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadBits(&entropy_coding_mode_flag, 1));
+  pps.entropy_coding_mode_flag = entropy_coding_mode_flag != 0;
+  // bottom_field_pic_order_in_frame_present_flag: u(1)
+  uint32_t bottom_field_pic_order_in_frame_present_flag;
+  RETURN_EMPTY_ON_FAIL(
+      bit_buffer->ReadBits(&bottom_field_pic_order_in_frame_present_flag, 1));
+  pps.bottom_field_pic_order_in_frame_present_flag =
+      bottom_field_pic_order_in_frame_present_flag != 0;
+
+  // num_slice_groups_minus1: ue(v)
+  uint32_t num_slice_groups_minus1;
+  RETURN_EMPTY_ON_FAIL(
+      bit_buffer->ReadExponentialGolomb(&num_slice_groups_minus1));
+  if (num_slice_groups_minus1 > 0) {
+    uint32_t slice_group_map_type;
+    // slice_group_map_type: ue(v)
+    RETURN_EMPTY_ON_FAIL(
+        bit_buffer->ReadExponentialGolomb(&slice_group_map_type));
+    if (slice_group_map_type == 0) {
+      for (uint32_t i_group = 0; i_group <= num_slice_groups_minus1;
+           ++i_group) {
+        // run_length_minus1[iGroup]: ue(v)
+        RETURN_EMPTY_ON_FAIL(
+            bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+      }
+    } else if (slice_group_map_type == 1) {
+      // TODO(sprang): Implement support for dispersed slice group map type.
+      // See 8.2.2.2 Specification for dispersed slice group map type.
+    } else if (slice_group_map_type == 2) {
+      for (uint32_t i_group = 0; i_group <= num_slice_groups_minus1;
+           ++i_group) {
+        // top_left[iGroup]: ue(v)
+        RETURN_EMPTY_ON_FAIL(
+            bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+        // bottom_right[iGroup]: ue(v)
+        RETURN_EMPTY_ON_FAIL(
+            bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+      }
+    } else if (slice_group_map_type == 3 || slice_group_map_type == 4 ||
+               slice_group_map_type == 5) {
+      // slice_group_change_direction_flag: u(1)
+      RETURN_EMPTY_ON_FAIL(bit_buffer->ReadBits(&bits_tmp, 1));
+      // slice_group_change_rate_minus1: ue(v)
+      RETURN_EMPTY_ON_FAIL(bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+    } else if (slice_group_map_type == 6) {
+      // pic_size_in_map_units_minus1: ue(v)
+      uint32_t pic_size_in_map_units_minus1;
+      RETURN_EMPTY_ON_FAIL(
+          bit_buffer->ReadExponentialGolomb(&pic_size_in_map_units_minus1));
+      uint32_t slice_group_id_bits = 0;
+      uint32_t num_slice_groups = num_slice_groups_minus1 + 1;
+      // If num_slice_groups is not a power of two an additional bit is required
+      // to account for the ceil() of log2() below.
+      if ((num_slice_groups & (num_slice_groups - 1)) != 0)
+        ++slice_group_id_bits;
+      while (num_slice_groups > 0) {
+        num_slice_groups >>= 1;
+        ++slice_group_id_bits;
+      }
+      for (uint32_t i = 0; i <= pic_size_in_map_units_minus1; i++) {
+        // slice_group_id[i]: u(v)
+        // Represented by ceil(log2(num_slice_groups_minus1 + 1)) bits.
+        RETURN_EMPTY_ON_FAIL(
+            bit_buffer->ReadBits(&bits_tmp, slice_group_id_bits));
+      }
+    }
+  }
+  // num_ref_idx_l0_default_active_minus1: ue(v)
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+  // num_ref_idx_l1_default_active_minus1: ue(v)
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+  // weighted_pred_flag: u(1)
+  uint32_t weighted_pred_flag;
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadBits(&weighted_pred_flag, 1));
+  pps.weighted_pred_flag = weighted_pred_flag != 0;
+  // weighted_bipred_idc: u(2)
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadBits(&pps.weighted_bipred_idc, 2));
+
+  // pic_init_qp_minus26: se(v)
+  RETURN_EMPTY_ON_FAIL(
+      bit_buffer->ReadSignedExponentialGolomb(&pps.pic_init_qp_minus26));
+  // Sanity-check parsed value
+  if (pps.pic_init_qp_minus26 > kMaxPicInitQpDeltaValue ||
+      pps.pic_init_qp_minus26 < kMinPicInitQpDeltaValue) {
+    RETURN_EMPTY_ON_FAIL(false);
+  }
+  // pic_init_qs_minus26: se(v)
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+  // chroma_qp_index_offset: se(v)
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadExponentialGolomb(&golomb_ignored));
+  // deblocking_filter_control_present_flag: u(1)
+  // constrained_intra_pred_flag: u(1)
+  RETURN_EMPTY_ON_FAIL(bit_buffer->ReadBits(&bits_tmp, 2));
+  // redundant_pic_cnt_present_flag: u(1)
+  RETURN_EMPTY_ON_FAIL(
+      bit_buffer->ReadBits(&pps.redundant_pic_cnt_present_flag, 1));
+
+  return pps;
+}
+
+bool H265PpsParser::ParsePpsIdsInternal(rtc::BitBuffer* bit_buffer,
+                                        uint32_t* pps_id,
+                                        uint32_t* sps_id) {
+  // pic_parameter_set_id: ue(v)
+  if (!bit_buffer->ReadExponentialGolomb(pps_id))
+    return false;
+  // seq_parameter_set_id: ue(v)
+  if (!bit_buffer->ReadExponentialGolomb(sps_id))
+    return false;
+  return true;
+}
+
+}  // namespace webrtc
\ No newline at end of file
diff --git a/common_video/h265/h265_pps_parser.h b/common_video/h265/h265_pps_parser.h
new file mode 100644
index 0000000000..b7ddc9627b
--- /dev/null
+++ b/common_video/h265/h265_pps_parser.h
@@ -0,0 +1,64 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_VIDEO_H265_PPS_PARSER_H_
+#define COMMON_VIDEO_H265_PPS_PARSER_H_
+
+#include "absl/types/optional.h"
+
+namespace rtc {
+class BitBuffer;
+}
+
+namespace webrtc {
+
+// A class for parsing out picture parameter set (PPS) data from a H265 NALU.
+class H265PpsParser {
+ public:
+  // The parsed state of the PPS. Only some select values are stored.
+  // Add more as they are actually needed.
+  struct PpsState {
+    PpsState() = default;
+
+    bool bottom_field_pic_order_in_frame_present_flag = false;
+    bool weighted_pred_flag = false;
+    bool entropy_coding_mode_flag = false;
+    uint32_t weighted_bipred_idc = false;
+    uint32_t redundant_pic_cnt_present_flag = 0;
+    int pic_init_qp_minus26 = 0;
+    uint32_t id = 0;
+    uint32_t sps_id = 0;
+  };
+
+  // Unpack RBSP and parse PPS state from the supplied buffer.
+  static absl::optional<PpsState> ParsePps(const uint8_t* data, size_t length);
+
+  static bool ParsePpsIds(const uint8_t* data,
+                          size_t length,
+                          uint32_t* pps_id,
+                          uint32_t* sps_id);
+
+  static absl::optional<uint32_t> ParsePpsIdFromSliceSegmentLayerRbsp(
+      const uint8_t* data,
+      size_t length,
+      uint8_t nalu_type);
+
+ protected:
+  // Parse the PPS state, for a bit buffer where RBSP decoding has already been
+  // performed.
+  static absl::optional<PpsState> ParseInternal(rtc::BitBuffer* bit_buffer);
+  static bool ParsePpsIdsInternal(rtc::BitBuffer* bit_buffer,
+                                  uint32_t* pps_id,
+                                  uint32_t* sps_id);
+};
+
+}  // namespace webrtc
+
+#endif  // COMMON_VIDEO_H265_PPS_PARSER_H_
\ No newline at end of file
diff --git a/common_video/h265/h265_sps_parser.cc b/common_video/h265/h265_sps_parser.cc
new file mode 100644
index 0000000000..d5732cbebe
--- /dev/null
+++ b/common_video/h265/h265_sps_parser.cc
@@ -0,0 +1,192 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <memory>
+#include <vector>
+
+#include "common_video/h265/h265_common.h"
+#include "common_video/h265/h265_sps_parser.h"
+#include "rtc_base/bit_buffer.h"
+#include "rtc_base/logging.h"
+
+namespace {
+typedef absl::optional<webrtc::H265SpsParser::SpsState> OptionalSps;
+
+#define RETURN_EMPTY_ON_FAIL(x) \
+  if (!(x)) {                   \
+    return OptionalSps();       \
+  }
+}  // namespace
+
+namespace webrtc {
+
+H265SpsParser::SpsState::SpsState() = default;
+
+// General note: this is based off the 02/2018 version of the H.265 standard.
+// You can find it on this page:
+// http://www.itu.int/rec/T-REC-H.265
+
+// Unpack RBSP and parse SPS state from the supplied buffer.
+absl::optional<H265SpsParser::SpsState> H265SpsParser::ParseSps(
+    const uint8_t* data,
+    size_t length) {
+  std::vector<uint8_t> unpacked_buffer = H265::ParseRbsp(data, length);
+  rtc::BitBuffer bit_buffer(unpacked_buffer.data(), unpacked_buffer.size());
+  return ParseSpsUpToVui(&bit_buffer);
+}
+
+absl::optional<H265SpsParser::SpsState> H265SpsParser::ParseSpsUpToVui(
+    rtc::BitBuffer* buffer) {
+  // Now, we need to use a bit buffer to parse through the actual HEVC SPS
+  // format. See Section 7.3.2.2.1 ("General sequence parameter set data
+  // syntax") of the H.265 standard for a complete description.
+  // Since we only care about resolution, we ignore the majority of fields, but
+  // we still have to actively parse through a lot of the data, since many of
+  // the fields have variable size.
+  // We're particularly interested in:
+  // chroma_format_idc -> affects crop units
+  // pic_{width,height}_* -> resolution of the frame in macroblocks (16x16).
+  // frame_crop_*_offset -> crop information
+
+  SpsState sps;
+
+  // The golomb values we have to read, not just consume.
+  uint32_t golomb_ignored;
+
+  // separate_colour_plane_flag is optional (assumed 0), but has implications
+  // about the ChromaArrayType, which modifies how we treat crop coordinates.
+  uint32_t separate_colour_plane_flag = 0;
+
+  // chroma_format_idc will be ChromaArrayType if separate_colour_plane_flag is
+  // 0. It defaults to 1, when not specified.
+  uint32_t chroma_format_idc = 1;
+
+  // sps_video_parameter_set_id: u(4)
+  uint32_t sps_video_parameter_set_id = 0;
+  RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&sps_video_parameter_set_id, 4));
+  // sps_max_sub_layers_minus1: u(3)
+  uint32_t sps_max_sub_layers_minus1 = 0;
+  RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&sps_max_sub_layers_minus1, 3));
+  // sps_temporal_id_nesting_flag: u(1)
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(1));
+  // profile_tier_level(1, sps_max_sub_layers_minus1). We are acutally not
+  // using them, so read/skip over it.
+  // general_profile_space+general_tier_flag+general_prfile_idc: u(8)
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBytes(1));
+  // general_profile_compatabilitiy_flag[32]
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBytes(4));
+  // general_progressive_source_flag + interlaced_source_flag+
+  // non-packed_constraint flag + frame_only_constraint_flag: u(4)
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(4));
+  // general_profile_idc decided flags or reserved.  u(43)
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(43));
+  // general_inbld_flag or reserved 0: u(1)
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(1));
+  // general_level_idc: u(8)
+  RETURN_EMPTY_ON_FAIL(buffer->ConsumeBytes(1));
+  // if max_sub_layers_minus1 >=1, read the sublayer profile information
+  std::vector<uint32_t> sub_layer_profile_present_flags;
+  std::vector<uint32_t> sub_layer_level_present_flags;
+  uint32_t sub_layer_profile_present = 0;
+  uint32_t sub_layer_level_present = 0;
+  for (uint32_t i = 0; i < sps_max_sub_layers_minus1; i++) {
+    // sublayer_profile_present_flag and sublayer_level_presnet_flag:  u(2)
+    RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&sub_layer_profile_present, 1));
+    RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&sub_layer_level_present, 1));
+    sub_layer_profile_present_flags.push_back(sub_layer_profile_present);
+    sub_layer_level_present_flags.push_back(sub_layer_level_present);
+  }
+  if (sps_max_sub_layers_minus1 > 0) {
+    for (uint32_t j = sps_max_sub_layers_minus1; j < 8; j++) {
+      // reserved 2 bits: u(2)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(2));
+    }
+  }
+  for (uint32_t k = 0; k < sps_max_sub_layers_minus1; k++) {
+    if (sub_layer_profile_present_flags[k]) {  //
+      // sub_layer profile_space/tier_flag/profile_idc. ignored. u(8)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBytes(1));
+      // profile_compatability_flag:  u(32)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBytes(4));
+      // sub_layer progressive_source_flag/interlaced_source_flag/
+      // non_packed_constraint_flag/frame_only_constraint_flag: u(4)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(4));
+      // following 43-bits are profile_idc specific. We simply read/skip it.
+      // u(43)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(43));
+      // 1-bit profile_idc specific inbld flag.  We simply read/skip it. u(1)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBits(1));
+    }
+    if (sub_layer_level_present_flags[k]) {
+      // sub_layer_level_idc: u(8)
+      RETURN_EMPTY_ON_FAIL(buffer->ConsumeBytes(1));
+    }
+  }
+  // sps_seq_parameter_set_id: ue(v)
+  RETURN_EMPTY_ON_FAIL(buffer->ReadExponentialGolomb(&golomb_ignored));
+  // chrome_format_idc: ue(v)
+  RETURN_EMPTY_ON_FAIL(buffer->ReadExponentialGolomb(&chroma_format_idc));
+  if (chroma_format_idc == 3) {
+    // seperate_colour_plane_flag: u(1)
+    RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&separate_colour_plane_flag, 1));
+  }
+  uint32_t pic_width_in_luma_samples = 0;
+  uint32_t pic_height_in_luma_samples = 0;
+  // pic_width_in_luma_samples: ue(v)
+  RETURN_EMPTY_ON_FAIL(
+      buffer->ReadExponentialGolomb(&pic_width_in_luma_samples));
+  // pic_height_in_luma_samples: ue(v)
+  RETURN_EMPTY_ON_FAIL(
+      buffer->ReadExponentialGolomb(&pic_height_in_luma_samples));
+  // conformance_window_flag: u(1)
+  uint32_t conformance_window_flag = 0;
+  RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&conformance_window_flag, 1));
+
+  uint32_t conf_win_left_offset = 0;
+  uint32_t conf_win_right_offset = 0;
+  uint32_t conf_win_top_offset = 0;
+  uint32_t conf_win_bottom_offset = 0;
+  if (conformance_window_flag) {
+    // conf_win_left_offset: ue(v)
+    RETURN_EMPTY_ON_FAIL(buffer->ReadExponentialGolomb(&conf_win_left_offset));
+    // conf_win_right_offset: ue(v)
+    RETURN_EMPTY_ON_FAIL(buffer->ReadExponentialGolomb(&conf_win_right_offset));
+    // conf_win_top_offset: ue(v)
+    RETURN_EMPTY_ON_FAIL(buffer->ReadExponentialGolomb(&conf_win_top_offset));
+    // conf_win_bottom_offset: ue(v)
+    RETURN_EMPTY_ON_FAIL(
+        buffer->ReadExponentialGolomb(&conf_win_bottom_offset));
+  }
+
+  // Far enough! We don't use the rest of the SPS.
+
+  sps.vps_id = sps_video_parameter_set_id;
+
+  // Start with the resolution determined by the pic_width/pic_height fields.
+  sps.width = pic_width_in_luma_samples;
+  sps.height = pic_height_in_luma_samples;
+
+  if (conformance_window_flag) {
+    int sub_width_c = ((1 == chroma_format_idc) || (2 == chroma_format_idc)) &&
+                              (0 == separate_colour_plane_flag)
+                          ? 2
+                          : 1;
+    int sub_height_c =
+        (1 == chroma_format_idc) && (0 == separate_colour_plane_flag) ? 2 : 1;
+    // the offset includes the pixel within conformance window. so don't need to
+    // +1 as per spec
+    sps.width -= sub_width_c * (conf_win_right_offset + conf_win_left_offset);
+    sps.height -= sub_height_c * (conf_win_top_offset + conf_win_bottom_offset);
+  }
+
+  return OptionalSps(sps);
+}
+
+}  // namespace webrtc
\ No newline at end of file
diff --git a/common_video/h265/h265_sps_parser.h b/common_video/h265/h265_sps_parser.h
new file mode 100644
index 0000000000..25c1c75cc4
--- /dev/null
+++ b/common_video/h265/h265_sps_parser.h
@@ -0,0 +1,54 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_VIDEO_H265_H265_SPS_PARSER_H_
+#define COMMON_VIDEO_H265_H265_SPS_PARSER_H_
+
+#include "absl/types/optional.h"
+
+namespace rtc {
+class BitBuffer;
+}
+
+namespace webrtc {
+
+// A class for parsing out sequence parameter set (SPS) data from an H265 NALU.
+class H265SpsParser {
+ public:
+  // The parsed state of the SPS. Only some select values are stored.
+  // Add more as they are actually needed.
+  struct SpsState {
+    SpsState();
+
+    uint32_t width = 0;
+    uint32_t height = 0;
+    uint32_t delta_pic_order_always_zero_flag = 0;
+    uint32_t separate_colour_plane_flag = 0;
+    uint32_t frame_mbs_only_flag = 0;
+    uint32_t log2_max_frame_num_minus4 = 0;
+    uint32_t log2_max_pic_order_cnt_lsb_minus4 = 0;
+    uint32_t pic_order_cnt_type = 0;
+    uint32_t max_num_ref_frames = 0;
+    uint32_t vui_params_present = 0;
+    uint32_t id = 0;
+    uint32_t vps_id = 0;
+  };
+
+  // Unpack RBSP and parse SPS state from the supplied buffer.
+  static absl::optional<SpsState> ParseSps(const uint8_t* data, size_t length);
+
+ protected:
+  // Parse the SPS state, up till the VUI part, for a bit buffer where RBSP
+  // decoding has already been performed.
+  static absl::optional<SpsState> ParseSpsUpToVui(rtc::BitBuffer* buffer);
+};
+
+}  // namespace webrtc
+#endif  // COMMON_VIDEO_H265_H265_SPS_PARSER_H_
\ No newline at end of file
diff --git a/common_video/h265/h265_vps_parser.cc b/common_video/h265/h265_vps_parser.cc
new file mode 100644
index 0000000000..59acb9d086
--- /dev/null
+++ b/common_video/h265/h265_vps_parser.cc
@@ -0,0 +1,62 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <memory>
+#include <vector>
+
+#include "common_video/h265/h265_common.h"
+#include "common_video/h265/h265_vps_parser.h"
+#include "rtc_base/bit_buffer.h"
+#include "rtc_base/logging.h"
+
+namespace {
+typedef absl::optional<webrtc::H265VpsParser::VpsState> OptionalVps;
+
+#define RETURN_EMPTY_ON_FAIL(x) \
+  if (!(x)) {                   \
+    return OptionalVps();       \
+  }
+}  // namespace
+
+namespace webrtc {
+
+H265VpsParser::VpsState::VpsState() = default;
+
+// General note: this is based off the 02/2018 version of the H.265 standard.
+// You can find it on this page:
+// http://www.itu.int/rec/T-REC-H.265
+
+// Unpack RBSP and parse SPS state from the supplied buffer.
+absl::optional<H265VpsParser::VpsState> H265VpsParser::ParseVps(
+    const uint8_t* data,
+    size_t length) {
+  std::vector<uint8_t> unpacked_buffer = H265::ParseRbsp(data, length);
+  rtc::BitBuffer bit_buffer(unpacked_buffer.data(), unpacked_buffer.size());
+  return ParseInternal(&bit_buffer);
+}
+
+absl::optional<H265VpsParser::VpsState> H265VpsParser::ParseInternal(
+    rtc::BitBuffer* buffer) {
+  // Now, we need to use a bit buffer to parse through the actual HEVC VPS
+  // format. See Section 7.3.2.1 ("Video parameter set RBSP syntax") of the
+  // H.265 standard for a complete description.
+
+  VpsState vps;
+
+  // vps_video_parameter_set_id: u(4)
+  uint32_t vps_video_parameter_set_id = 0;
+  RETURN_EMPTY_ON_FAIL(buffer->ReadBits(&vps_video_parameter_set_id, 4));
+
+  vps.id = vps_video_parameter_set_id;
+  vps.id = 0;
+  return OptionalVps(vps);
+}
+
+}  // namespace webrtc
\ No newline at end of file
diff --git a/common_video/h265/h265_vps_parser.h b/common_video/h265/h265_vps_parser.h
new file mode 100644
index 0000000000..0b7c1af511
--- /dev/null
+++ b/common_video/h265/h265_vps_parser.h
@@ -0,0 +1,43 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef COMMON_VIDEO_H265_H265_VPS_PARSER_H_
+#define COMMON_VIDEO_H265_H265_VPS_PARSER_H_
+
+#include "absl/types/optional.h"
+
+namespace rtc {
+class BitBuffer;
+}
+
+namespace webrtc {
+
+// A class for parsing out sequence parameter set (VPS) data from an H265 NALU.
+class H265VpsParser {
+ public:
+  // The parsed state of the VPS. Only some select values are stored.
+  // Add more as they are actually needed.
+  struct VpsState {
+    VpsState();
+
+    uint32_t id = 0;
+  };
+
+  // Unpack RBSP and parse VPS state from the supplied buffer.
+  static absl::optional<VpsState> ParseVps(const uint8_t* data, size_t length);
+
+ protected:
+  // Parse the VPS state, for a bit buffer where RBSP decoding has already been
+  // performed.
+  static absl::optional<VpsState> ParseInternal(rtc::BitBuffer* bit_buffer);
+};
+
+}  // namespace webrtc
+#endif  // COMMON_VIDEO_H265_H265_VPS_PARSER_H_
\ No newline at end of file
diff --git a/logging/rtc_event_log/encoder/rtc_event_log_encoder_new_format.cc b/logging/rtc_event_log/encoder/rtc_event_log_encoder_new_format.cc
index 8891396a2c..10068cf2e5 100644
--- a/logging/rtc_event_log/encoder/rtc_event_log_encoder_new_format.cc
+++ b/logging/rtc_event_log/encoder/rtc_event_log_encoder_new_format.cc
@@ -104,6 +104,7 @@ rtclog2::FrameDecodedEvents::Codec ConvertToProtoFormat(VideoCodecType codec) {
       return rtclog2::FrameDecodedEvents::CODEC_AV1;
     case VideoCodecType::kVideoCodecH264:
       return rtclog2::FrameDecodedEvents::CODEC_H264;
+    case VideoCodecType::kVideoCodecH265:
     case VideoCodecType::kVideoCodecMultiplex:
       // This codec type is afaik not used.
       return rtclog2::FrameDecodedEvents::CODEC_UNKNOWN;
diff --git a/media/base/media_constants.cc b/media/base/media_constants.cc
index 5abb744a5c..fe5a6d1a01 100644
--- a/media/base/media_constants.cc
+++ b/media/base/media_constants.cc
@@ -104,6 +104,7 @@ const char kVp8CodecName[] = "VP8";
 const char kVp9CodecName[] = "VP9";
 const char kAv1CodecName[] = "AV1X";
 const char kH264CodecName[] = "H264";
+const char kH265CodecName[] = "H265";
 
 // RFC 6184 RTP Payload Format for H.264 video
 const char kH264FmtpProfileLevelId[] = "profile-level-id";
@@ -114,6 +115,12 @@ const char kH264FmtpSpsPpsIdrInKeyframe[] = "sps-pps-idr-in-keyframe";
 const char kH264ProfileLevelConstrainedBaseline[] = "42e01f";
 const char kH264ProfileLevelConstrainedHigh[] = "640c1f";
 
+// RFC 7798 RTP Payload Format for H.265 video
+const char kH265FmtpProfileSpace[] = "profile-space";
+const char kH265FmtpProfileId[] = "profile-id";
+const char kH265FmtpTierFlag[] = "tier-flag";
+const char kH265FmtpLevelId[] = "level-id";
+
 const int kDefaultVideoMaxFramerate = 60;
 
 const size_t kConferenceMaxNumSpatialLayers = 3;
diff --git a/media/base/media_constants.h b/media/base/media_constants.h
index 37e177aeb4..4e57f15feb 100644
--- a/media/base/media_constants.h
+++ b/media/base/media_constants.h
@@ -130,6 +130,7 @@ RTC_EXPORT extern const char kVp8CodecName[];
 RTC_EXPORT extern const char kVp9CodecName[];
 RTC_EXPORT extern const char kAv1CodecName[];
 RTC_EXPORT extern const char kH264CodecName[];
+RTC_EXPORT extern const char kH265CodecName[];
 
 // RFC 6184 RTP Payload Format for H.264 video
 RTC_EXPORT extern const char kH264FmtpProfileLevelId[];
@@ -140,6 +141,12 @@ extern const char kH264FmtpSpsPpsIdrInKeyframe[];
 extern const char kH264ProfileLevelConstrainedBaseline[];
 extern const char kH264ProfileLevelConstrainedHigh[];
 
+// RFC 7798 RTP Payload Format for H.265 video
+RTC_EXPORT extern const char kH265FmtpProfileSpace[];
+RTC_EXPORT extern const char kH265FmtpProfileId[];
+RTC_EXPORT extern const char kH265FmtpTierFlag[];
+RTC_EXPORT extern const char kH265FmtpLevelId[];
+
 extern const int kDefaultVideoMaxFramerate;
 
 extern const size_t kConferenceMaxNumSpatialLayers;
diff --git a/modules/audio_device/BUILD.gn b/modules/audio_device/BUILD.gn
index 4f701e4be8..4e17d136bc 100644
--- a/modules/audio_device/BUILD.gn
+++ b/modules/audio_device/BUILD.gn
@@ -293,6 +293,7 @@ rtc_library("audio_device_impl") {
         ]
       }
       if (is_mac) {
+        cflags += [ "-Wno-deprecated-declarations" ]
         sources += [
           "mac/audio_device_mac.cc",
           "mac/audio_device_mac.h",
diff --git a/modules/desktop_capture/BUILD.gn b/modules/desktop_capture/BUILD.gn
index 735616b633..a3cacfe393 100644
--- a/modules/desktop_capture/BUILD.gn
+++ b/modules/desktop_capture/BUILD.gn
@@ -240,6 +240,7 @@ rtc_source_set("desktop_capture") {
 if (is_mac) {
   rtc_library("desktop_capture_objc") {
     visibility = [ ":desktop_capture" ]
+    cflags = [ "-Wno-deprecated-declarations" ]
     sources = [
       "mac/desktop_configuration.mm",
       "mac/desktop_frame_cgimage.h",
diff --git a/modules/rtp_rtcp/BUILD.gn b/modules/rtp_rtcp/BUILD.gn
index e7efb41715..2d21f3f3ca 100644
--- a/modules/rtp_rtcp/BUILD.gn
+++ b/modules/rtp_rtcp/BUILD.gn
@@ -243,6 +243,11 @@ rtc_library("rtp_rtcp") {
     defines = [ "BWE_TEST_LOGGING_COMPILE_TIME_ENABLE=0" ]
   }
 
+  sources += [
+    "source/rtp_format_h265.cc",
+    "source/rtp_format_h265.h",
+  ]
+
   deps = [
     ":rtp_rtcp_format",
     ":rtp_video_header",
diff --git a/modules/rtp_rtcp/source/create_video_rtp_depacketizer.cc b/modules/rtp_rtcp/source/create_video_rtp_depacketizer.cc
index 724ad8c42e..c5ce3ed746 100644
--- a/modules/rtp_rtcp/source/create_video_rtp_depacketizer.cc
+++ b/modules/rtp_rtcp/source/create_video_rtp_depacketizer.cc
@@ -13,6 +13,7 @@
 #include <memory>
 
 #include "api/video/video_codec_type.h"
+#include "modules/rtp_rtcp/source/rtp_format_h265.h"
 #include "modules/rtp_rtcp/source/video_rtp_depacketizer.h"
 #include "modules/rtp_rtcp/source/video_rtp_depacketizer_av1.h"
 #include "modules/rtp_rtcp/source/video_rtp_depacketizer_generic.h"
@@ -27,6 +28,8 @@ std::unique_ptr<VideoRtpDepacketizer> CreateVideoRtpDepacketizer(
   switch (codec) {
     case kVideoCodecH264:
       return std::make_unique<VideoRtpDepacketizerH264>();
+    case kVideoCodecH265:
+      return std::make_unique<VideoRtpDepacketizerH265>();
     case kVideoCodecVP8:
       return std::make_unique<VideoRtpDepacketizerVp8>();
     case kVideoCodecVP9:
diff --git a/modules/rtp_rtcp/source/h265_sps_parser.cc b/modules/rtp_rtcp/source/h265_sps_parser.cc
new file mode 100644
index 0000000000..22c6f9d30c
--- /dev/null
+++ b/modules/rtp_rtcp/source/h265_sps_parser.cc
@@ -0,0 +1,191 @@
+/*
+ * Intel License
+ * See https://01.org/open-webrtc-toolkit
+ * This is released under Apache License 2.0 and it is free for both academic and commercial use.
+ */
+
+#include "webrtc/modules/rtp_rtcp/source/h265_sps_parser.h"
+
+#include "rtc_base/bit_buffer.h"
+#include "rtc_base/byte_buffer.h"
+#include "rtc_base/logging.h"
+
+#include <vector>
+
+#define RETURN_FALSE_ON_FAIL(x) \
+  if (!(x)) {                   \
+    return false;               \
+  }
+
+namespace webrtc {
+
+H265SpsParser::H265SpsParser(const uint8_t* sps, size_t byte_length)
+    : sps_(sps), byte_length_(byte_length), width_(), height_() {
+}
+
+bool H265SpsParser::Parse() {
+  // General note: this is based off the 04/2015 version of the H.265 standard.
+  // You can find it on this page:
+  // http://www.itu.int/rec/T-REC-H.265
+
+  const char* sps_bytes = reinterpret_cast<const char*>(sps_);
+  // First, parse out rbsp, which is basically the source buffer minus emulation
+  // bytes (the last byte of a 0x00 0x00 0x03 sequence). RBSP is defined in
+  // section 7.3.1.1 of the H.265 standard, similar to H264.
+  rtc::ByteBufferWriter rbsp_buffer;
+  for (size_t i = 0; i < byte_length_;) {
+    // Be careful about over/underflow here. byte_length_ - 3 can underflow, and
+    // i + 3 can overflow, but byte_length_ - i can't, because i < byte_length_
+    // above, and that expression will produce the number of bytes left in
+    // the stream including the byte at i.
+    if (byte_length_ - i >= 3 && sps_[i] == 0 && sps_[i + 1] == 0 &&
+        sps_[i + 2] == 3) {
+      // Two rbsp bytes + the emulation byte.
+      rbsp_buffer.WriteBytes(sps_bytes + i, 2);
+      i += 3;
+    } else {
+      // Single rbsp byte.
+      rbsp_buffer.WriteBytes(sps_bytes + i, 1);
+      i++;
+    }
+  }
+
+  // Now, we need to use a bit buffer to parse through the actual HEVC SPS
+  // format. See Section 7.3.2.1.1 ("Sequence parameter set data syntax") of the
+  // H.265 standard for a complete description.
+  // Since we only care about resolution, we ignore the majority of fields, but
+  // we still have to actively parse through a lot of the data, since many of
+  // the fields have variable size.
+  // Unlike H264, for H265, the picture size is indicated by pic_width_in_luma_samples
+  // and pic_height_in_luma_samples,  if conformance_window_flag !=1;
+  // When conformance_window_flag is 1,  the width is adjusted with con_win_xx_offset
+  //
+  rtc::BitBuffer parser(reinterpret_cast<const uint8_t*>(rbsp_buffer.Data()),
+                        rbsp_buffer.Length());
+
+  // The golomb values we have to read, not just consume.
+  uint32_t golomb_ignored;
+
+  // separate_colour_plane_flag is optional (assumed 0), but has implications
+  // about the ChromaArrayType, which modifies how we treat crop coordinates.
+  uint32_t separate_colour_plane_flag = 0;
+  // chroma_format_idc will be ChromaArrayType if separate_colour_plane_flag is
+  // 0. It defaults to 1, when not specified.
+  uint32_t chroma_format_idc = 1;
+
+
+  // sps_video_parameter_set_id: u(4)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBits(4));
+  // sps_max_sub_layers_minus1: u(3)
+  uint32_t sps_max_sub_layers_minus1 = 0;
+  RETURN_FALSE_ON_FAIL(parser.ReadBits(&sps_max_sub_layers_minus1, 3));
+  // sps_temporal_id_nesting_flag: u(1)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBits(1));
+  // profile_tier_level(1, sps_max_sub_layers_minus1). We are acutally not
+  // using them, so read/skip over it.
+  // general_profile_space+general_tier_flag+general_prfile_idc: u(8)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBytes(1));
+  // general_profile_compatabilitiy_flag[32]
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBytes(4));
+  // general_progressive_source_flag + interlaced_source_flag+ non-packed_constraint
+  // flag + frame_only_constraint_flag: u(4)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBits(4));
+  // general_profile_idc decided flags or reserved.  u(43)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBits(43));
+  // general_inbld_flag or reserved 0: u(1)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBits(1));
+  // general_level_idc: u(8)
+  RETURN_FALSE_ON_FAIL(parser.ConsumeBytes(1));
+  // if max_sub_layers_minus1 >=1, read the sublayer profile information
+  std::vector<uint32_t> sub_layer_profile_present_flags;
+  std::vector<uint32_t> sub_layer_level_present_flags;
+  uint32_t sub_layer_profile_present = 0;
+  uint32_t sub_layer_level_present = 0;
+  for (uint32_t i = 0; i < sps_max_sub_layers_minus1; i++) {
+      //sublayer_profile_present_flag and sublayer_level_presnet_flag:  u(2)
+      RETURN_FALSE_ON_FAIL(parser.ReadBits(&sub_layer_profile_present, 1));
+      RETURN_FALSE_ON_FAIL(parser.ReadBits(&sub_layer_level_present, 1));
+      sub_layer_profile_present_flags.push_back(sub_layer_profile_present);
+      sub_layer_level_present_flags.push_back(sub_layer_level_present);
+  }
+  if (sps_max_sub_layers_minus1 > 0) {
+      for (uint32_t j = sps_max_sub_layers_minus1; j < 8; j++) {
+        // reserved 2 bits: u(2)
+          RETURN_FALSE_ON_FAIL(parser.ConsumeBits(2));
+      }
+  }
+  for (uint32_t k = 0; k < sps_max_sub_layers_minus1; k++) {
+      if(sub_layer_profile_present_flags[k]) {//
+        // sub_layer profile_space/tier_flag/profile_idc. ignored. u(8)
+        RETURN_FALSE_ON_FAIL(parser.ConsumeBytes(1));
+        // profile_compatability_flag:  u(32)
+        RETURN_FALSE_ON_FAIL(parser.ConsumeBytes(4));
+        // sub_layer progressive_source_flag/interlaced_source_flag/
+        // non_packed_constraint_flag/frame_only_constraint_flag: u(4)
+        RETURN_FALSE_ON_FAIL(parser.ConsumeBits(4));
+        // following 43-bits are profile_idc specific. We simply read/skip it. u(43)
+        RETURN_FALSE_ON_FAIL(parser.ConsumeBits(43));
+        // 1-bit profile_idc specific inbld flag.  We simply read/skip it. u(1)
+        RETURN_FALSE_ON_FAIL(parser.ConsumeBits(1));
+      }
+      if (sub_layer_level_present_flags[k]) {
+        // sub_layer_level_idc: u(8)
+          RETURN_FALSE_ON_FAIL(parser.ConsumeBytes(1));
+      }
+  }
+  //sps_seq_parameter_set_id: ue(v)
+  RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&golomb_ignored));
+  // chrome_format_idc: ue(v)
+  RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&chroma_format_idc));
+  if (chroma_format_idc == 3) {
+    // seperate_colour_plane_flag: u(1)
+    RETURN_FALSE_ON_FAIL(parser.ReadBits(&separate_colour_plane_flag, 1));
+  }
+  uint32_t pic_width_in_luma_samples = 0;
+  uint32_t pic_height_in_luma_samples = 0;
+  // pic_width_in_luma_samples: ue(v)
+  RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&pic_width_in_luma_samples));
+  // pic_height_in_luma_samples: ue(v)
+  RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&pic_height_in_luma_samples));
+  // conformance_window_flag: u(1)
+  uint32_t conformance_window_flag = 0;
+  RETURN_FALSE_ON_FAIL(parser.ReadBits(&conformance_window_flag, 1));
+
+  uint32_t conf_win_left_offset = 0;
+  uint32_t conf_win_right_offset = 0;
+  uint32_t conf_win_top_offset = 0;
+  uint32_t conf_win_bottom_offset = 0;
+  if (conformance_window_flag) {
+      // conf_win_left_offset: ue(v)
+      RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&conf_win_left_offset));
+      // conf_win_right_offset: ue(v)
+      RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&conf_win_right_offset));
+      // conf_win_top_offset: ue(v)
+      RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&conf_win_top_offset));
+      // conf_win_bottom_offset: ue(v)
+      RETURN_FALSE_ON_FAIL(parser.ReadExponentialGolomb(&conf_win_bottom_offset));
+  }
+
+  //For enough to get the resolution information. calcaluate according to HEVC spec 7.4.3.2
+  int width = 0;
+  int height = 0;
+
+  width = pic_width_in_luma_samples;
+  height = pic_height_in_luma_samples;
+
+  if (conformance_window_flag) {
+    int sub_width_c = ((1 == chroma_format_idc) || (2 == chroma_format_idc)) &&
+                        (0 == separate_colour_plane_flag) ? 2 : 1;
+    int sub_height_c = (1 == chroma_format_idc) && (0 == separate_colour_plane_flag) ? 2 : 1;
+    //the offset includes the pixel within conformance window. so don't need to +1 as per spec
+    width -= sub_width_c*(conf_win_right_offset + conf_win_left_offset);
+    height -= sub_height_c*(conf_win_top_offset + conf_win_bottom_offset);
+  }
+
+  width_ = width;
+  height_ = height;
+  return true;
+
+}
+
+}  // namespace webrtc
\ No newline at end of file
diff --git a/modules/rtp_rtcp/source/h265_sps_parser.h b/modules/rtp_rtcp/source/h265_sps_parser.h
new file mode 100644
index 0000000000..1e62b58977
--- /dev/null
+++ b/modules/rtp_rtcp/source/h265_sps_parser.h
@@ -0,0 +1,34 @@
+/*
+ *  Intel License
+ * See https://01.org/open-webrtc-toolkit
+ * This is released under Apache License 2.0 and it is free for both academic and commercial use.
+ */
+
+#ifndef WEBRTC_MODULES_RTP_RTCP_SOURCE_H265_SPS_PARSER_H_
+#define WEBRTC_MODULES_RTP_RTCP_SOURCE_H265_SPS_PARSER_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+namespace webrtc {
+
+// A class for parsing out sequence parameter set (SPS) data from an H265 NALU.
+// Currently, only resolution is read without being ignored.
+class H265SpsParser {
+ public:
+  H265SpsParser(const uint8_t* sps, size_t byte_length);
+  // Parses the SPS to completion. Returns true if the SPS was parsed correctly.
+  bool Parse();
+  uint16_t width() { return width_; }
+  uint16_t height() { return height_; }
+
+ private:
+  const uint8_t* const sps_;
+  const size_t byte_length_;
+
+  uint16_t width_;
+  uint16_t height_;
+};
+
+}  // namespace webrtc
+#endif  // WEBRTC_MODULES_RTP_RTCP_SOURCE_H265_SPS_PARSER_H_
\ No newline at end of file
diff --git a/modules/rtp_rtcp/source/rtp_format.cc b/modules/rtp_rtcp/source/rtp_format.cc
index 7703a6bf0f..56dded309d 100644
--- a/modules/rtp_rtcp/source/rtp_format.cc
+++ b/modules/rtp_rtcp/source/rtp_format.cc
@@ -14,11 +14,13 @@
 
 #include "absl/types/variant.h"
 #include "modules/rtp_rtcp/source/rtp_format_h264.h"
+#include "modules/rtp_rtcp/source/rtp_format_h265.h"
 #include "modules/rtp_rtcp/source/rtp_format_video_generic.h"
 #include "modules/rtp_rtcp/source/rtp_format_vp8.h"
 #include "modules/rtp_rtcp/source/rtp_format_vp9.h"
 #include "modules/rtp_rtcp/source/rtp_packetizer_av1.h"
 #include "modules/video_coding/codecs/h264/include/h264_globals.h"
+#include "modules/video_coding/codecs/h265/include/h265_globals.h"
 #include "modules/video_coding/codecs/vp8/include/vp8_globals.h"
 #include "modules/video_coding/codecs/vp9/include/vp9_globals.h"
 #include "rtc_base/checks.h"
@@ -43,6 +45,12 @@ std::unique_ptr<RtpPacketizer> RtpPacketizer::Create(
       return std::make_unique<RtpPacketizerH264>(payload, limits,
                                                  h264.packetization_mode);
     }
+    case kVideoCodecH265: {
+      const auto& h265 =
+          absl::get<RTPVideoHeaderH265>(rtp_video_header.video_type_header);
+      return absl::make_unique<RtpPacketizerH265>(payload, limits,
+                                                  h265.packetization_mode);
+    }
     case kVideoCodecVP8: {
       const auto& vp8 =
           absl::get<RTPVideoHeaderVP8>(rtp_video_header.video_type_header);
diff --git a/modules/rtp_rtcp/source/rtp_format_h265.cc b/modules/rtp_rtcp/source/rtp_format_h265.cc
new file mode 100644
index 0000000000..4ba16832f9
--- /dev/null
+++ b/modules/rtp_rtcp/source/rtp_format_h265.cc
@@ -0,0 +1,649 @@
+/*
+ *  Intel License
+ * See https://01.org/open-webrtc-toolkit
+ * This is released under Apache License 2.0 and it is free for both academic and commercial use.
+ */
+
+#include <string.h>
+
+#include "common_video/h264/h264_common.h"
+#include "common_video/h265/h265_common.h"
+#include "common_video/h265/h265_pps_parser.h"
+#include "common_video/h265/h265_sps_parser.h"
+#include "common_video/h265/h265_vps_parser.h"
+#include "modules/include/module_common_types.h"
+#include "modules/rtp_rtcp/source/byte_io.h"
+#include "modules/rtp_rtcp/source/rtp_format_h265.h"
+#include "modules/rtp_rtcp/source/rtp_packet_to_send.h"
+#include "rtc_base/logging.h"
+using namespace rtc;
+
+namespace webrtc {
+namespace {
+
+enum NaluType {
+  kTrailN = 0,
+  kTrailR = 1,
+  kTsaN = 2,
+  kTsaR = 3,
+  kStsaN = 4,
+  kStsaR = 5,
+  kRadlN = 6,
+  kRadlR = 7,
+  kBlaWLp = 16,
+  kBlaWRadl = 17,
+  kBlaNLp = 18,
+  kIdrWRadl = 19,
+  kIdrNLp = 20,
+  kCra = 21,
+  kVps = 32,
+  kHevcSps = 33,
+  kHevcPps = 34,
+  kHevcAud = 35,
+  kPrefixSei = 39,
+  kSuffixSei = 40,
+  kHevcAp = 48,
+  kHevcFu = 49
+};
+
+/*
+   0                   1                   2                   3
+   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  |    PayloadHdr (Type=49)       |   FU header   | DONL (cond)   |
+  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-|
+*/
+// Unlike H.264, HEVC NAL header is 2-bytes.
+static const size_t kHevcNalHeaderSize = 2;
+// H.265's FU is constructed of 2-byte payload header, and 1-byte FU header
+static const size_t kHevcFuHeaderSize = 1;
+static const size_t kHevcLengthFieldSize = 2;
+static const size_t kHevcApHeaderSize =
+    kHevcNalHeaderSize + kHevcLengthFieldSize;
+
+enum HevcNalHdrMasks {
+  kHevcFBit = 0x80,
+  kHevcTypeMask = 0x7E,
+  kHevcLayerIDHMask = 0x1,
+  kHevcLayerIDLMask = 0xF8,
+  kHevcTIDMask = 0x7,
+  kHevcTypeMaskN = 0x81,
+  kHevcTypeMaskInFuHeader = 0x3F
+};
+
+// Bit masks for FU headers.
+enum HevcFuDefs { kHevcSBit = 0x80, kHevcEBit = 0x40, kHevcFuTypeBit = 0x3F };
+
+// TODO(pbos): Avoid parsing this here as well as inside the jitter buffer.
+bool ParseApStartOffsets(const uint8_t* nalu_ptr,
+                         size_t length_remaining,
+                         std::vector<size_t>* offsets) {
+  size_t offset = 0;
+  while (length_remaining > 0) {
+    // Buffer doesn't contain room for additional nalu length.
+    if (length_remaining < sizeof(uint16_t))
+      return false;
+    uint16_t nalu_size = ByteReader<uint16_t>::ReadBigEndian(nalu_ptr);
+    nalu_ptr += sizeof(uint16_t);
+    length_remaining -= sizeof(uint16_t);
+    if (nalu_size > length_remaining)
+      return false;
+    nalu_ptr += nalu_size;
+    length_remaining -= nalu_size;
+
+    offsets->push_back(offset + kHevcApHeaderSize);
+    offset += kHevcLengthFieldSize + nalu_size;
+  }
+  return true;
+}
+
+}  // namespace
+
+RtpPacketizerH265::RtpPacketizerH265(
+    rtc::ArrayView<const uint8_t> payload,
+    PayloadSizeLimits limits,
+    H265PacketizationMode packetization_mode)
+    : limits_(limits),
+      num_packets_left_(0) {
+  // Guard against uninitialized memory in packetization_mode.
+  RTC_CHECK(packetization_mode == H265PacketizationMode::NonInterleaved ||
+            packetization_mode == H265PacketizationMode::SingleNalUnit);
+
+  for (const auto& nalu :
+       H264::FindNaluIndices(payload.data(), payload.size())) {
+    input_fragments_.push_back(
+        payload.subview(nalu.payload_start_offset, nalu.payload_size));
+  }
+
+  if (!GeneratePackets(packetization_mode)) {
+    // If failed to generate all the packets, discard already generated
+    // packets in case the caller would ignore return value and still try to
+    // call NextPacket().
+    num_packets_left_ = 0;
+    while (!packets_.empty()) {
+      packets_.pop();
+    }
+  }
+}
+
+RtpPacketizerH265::~RtpPacketizerH265() {}
+
+size_t RtpPacketizerH265::NumPackets() const {
+  return num_packets_left_;
+}
+
+RtpPacketizerH265::Fragment::Fragment(const uint8_t* buffer, size_t length)
+    : buffer(buffer), length(length) {}
+RtpPacketizerH265::Fragment::Fragment(const Fragment& fragment)
+    : buffer(fragment.buffer), length(fragment.length) {}
+
+
+bool RtpPacketizerH265::GeneratePackets(
+    H265PacketizationMode packetization_mode) {
+  // For HEVC we follow non-interleaved mode for the packetization,
+  // and don't support single-nalu mode at present.
+  for (size_t i = 0; i < input_fragments_.size();) {
+    int fragment_len = input_fragments_[i].size();
+    int single_packet_capacity = limits_.max_payload_len;
+    if (input_fragments_.size() == 1)
+      single_packet_capacity -= limits_.single_packet_reduction_len;
+    else if (i == 0)
+      single_packet_capacity -= limits_.first_packet_reduction_len;
+    else if (i + 1 == input_fragments_.size()) {
+      // Pretend that last fragment is larger instead of making last packet
+      // smaller.
+      single_packet_capacity -= limits_.last_packet_reduction_len;
+    }
+    if (fragment_len > single_packet_capacity) {
+      PacketizeFu(i);
+      ++i;
+    } else {
+      PacketizeSingleNalu(i);
+      ++i;
+    }
+  }
+  return true;
+}
+
+bool RtpPacketizerH265::PacketizeFu(size_t fragment_index) {
+  // Fragment payload into packets (FU).
+  // Strip out the original header and leave room for the FU header.
+  rtc::ArrayView<const uint8_t> fragment = input_fragments_[fragment_index];
+  PayloadSizeLimits limits = limits_;
+  limits.max_payload_len -= kHevcFuHeaderSize + kHevcNalHeaderSize;
+
+  // Update single/first/last packet reductions unless it is single/first/last
+  // fragment.
+  if (input_fragments_.size() != 1) {
+    // if this fragment is put into a single packet, it might still be the
+    // first or the last packet in the whole sequence of packets.
+    if (fragment_index == input_fragments_.size() - 1) {
+      limits.single_packet_reduction_len = limits_.last_packet_reduction_len;
+    } else if (fragment_index == 0) {
+      limits.single_packet_reduction_len = limits_.first_packet_reduction_len;
+    } else {
+      limits.single_packet_reduction_len = 0;
+    }
+  }
+  if (fragment_index != 0)
+    limits.first_packet_reduction_len = 0;
+  if (fragment_index != input_fragments_.size() - 1)
+    limits.last_packet_reduction_len = 0;
+
+  // Strip out the original header.
+  size_t payload_left = fragment.size() - kHevcNalHeaderSize;
+  int offset = kHevcNalHeaderSize;
+
+  std::vector<int> payload_sizes = SplitAboutEqually(payload_left, limits);
+  if (payload_sizes.empty())
+    return false;
+
+  for (size_t i = 0; i < payload_sizes.size(); ++i) {
+    int packet_length = payload_sizes[i];
+    RTC_CHECK_GT(packet_length, 0);
+    uint16_t header = (fragment[0] << 8) | fragment[1];
+    packets_.push(PacketUnit(fragment.subview(offset, packet_length),
+                             /*first_fragment=*/i == 0,
+                             /*last_fragment=*/i == payload_sizes.size() - 1,
+                             false, header));
+    offset += packet_length;
+    payload_left -= packet_length;
+  }
+  num_packets_left_ += payload_sizes.size();
+  RTC_CHECK_EQ(0, payload_left);
+  return true;
+}
+
+
+bool RtpPacketizerH265::PacketizeSingleNalu(size_t fragment_index) {
+  // Add a single NALU to the queue, no aggregation.
+  size_t payload_size_left = limits_.max_payload_len;
+  if (input_fragments_.size() == 1)
+    payload_size_left -= limits_.single_packet_reduction_len;
+  else if (fragment_index == 0)
+    payload_size_left -= limits_.first_packet_reduction_len;
+  else if (fragment_index + 1 == input_fragments_.size())
+    payload_size_left -= limits_.last_packet_reduction_len;
+  rtc::ArrayView<const uint8_t> fragment = input_fragments_[fragment_index];
+  if (payload_size_left < fragment.size()) {
+    RTC_LOG(LS_ERROR) << "Failed to fit a fragment to packet in SingleNalu "
+                         "packetization mode. Payload size left "
+                      << payload_size_left << ", fragment length "
+                      << fragment.size() << ", packet capacity "
+                      << limits_.max_payload_len;
+    return false;
+  }
+  RTC_CHECK_GT(fragment.size(), 0u);
+  packets_.push(PacketUnit(fragment, true /* first */, true /* last */,
+                           false /* aggregated */, fragment[0]));
+  ++num_packets_left_;
+  return true;
+}
+
+int RtpPacketizerH265::PacketizeAp(size_t fragment_index) {
+  // Aggregate fragments into one packet (STAP-A).
+  size_t payload_size_left = limits_.max_payload_len;
+  if (input_fragments_.size() == 1)
+    payload_size_left -= limits_.single_packet_reduction_len;
+  else if (fragment_index == 0)
+    payload_size_left -= limits_.first_packet_reduction_len;
+  int aggregated_fragments = 0;
+  size_t fragment_headers_length = 0;
+  rtc::ArrayView<const uint8_t> fragment = input_fragments_[fragment_index];
+  RTC_CHECK_GE(payload_size_left, fragment.size());
+  ++num_packets_left_;
+
+  auto payload_size_needed = [&] {
+    size_t fragment_size = fragment.size() + fragment_headers_length;
+    if (input_fragments_.size() == 1) {
+      // Single fragment, single packet, payload_size_left already adjusted
+      // with limits_.single_packet_reduction_len.
+      return fragment_size;
+    }
+    if (fragment_index == input_fragments_.size() - 1) {
+      // Last fragment, so StrapA might be the last packet.
+      return fragment_size + limits_.last_packet_reduction_len;
+    }
+    return fragment_size;
+  };
+
+  while (payload_size_left >= payload_size_needed()) {
+    RTC_CHECK_GT(fragment.size(), 0);
+    packets_.push(PacketUnit(fragment, aggregated_fragments == 0, false, true,
+                             fragment[0]));
+    payload_size_left -= fragment.size();
+    payload_size_left -= fragment_headers_length;
+
+    fragment_headers_length = kHevcLengthFieldSize;
+    // If we are going to try to aggregate more fragments into this packet
+    // we need to add the STAP-A NALU header and a length field for the first
+    // NALU of this packet.
+    if (aggregated_fragments == 0)
+      fragment_headers_length += kHevcNalHeaderSize + kHevcLengthFieldSize;
+    ++aggregated_fragments;
+
+    // Next fragment.
+    ++fragment_index;
+    if (fragment_index == input_fragments_.size())
+      break;
+    fragment = input_fragments_[fragment_index];
+  }
+  RTC_CHECK_GT(aggregated_fragments, 0);
+  packets_.back().last_fragment = true;
+  return fragment_index;
+}
+
+bool RtpPacketizerH265::NextPacket(RtpPacketToSend* rtp_packet) {
+  RTC_DCHECK(rtp_packet);
+
+  if (packets_.empty()) {
+    return false;
+  }
+
+  PacketUnit packet = packets_.front();
+
+  if (packet.first_fragment && packet.last_fragment) {
+    // Single NAL unit packet.
+    size_t bytes_to_send = packet.source_fragment.size();
+    uint8_t* buffer = rtp_packet->AllocatePayload(bytes_to_send);
+    memcpy(buffer, packet.source_fragment.data(), bytes_to_send);
+    packets_.pop();
+    input_fragments_.pop_front();
+  } else if (packet.aggregated) {
+    bool is_last_packet = num_packets_left_ == 1;
+    NextAggregatePacket(rtp_packet, is_last_packet);
+  } else {
+    NextFragmentPacket(rtp_packet);
+  }
+  rtp_packet->SetMarker(packets_.empty());
+  --num_packets_left_;
+  return true;
+}
+
+void RtpPacketizerH265::NextAggregatePacket(RtpPacketToSend* rtp_packet,
+                                            bool last) {
+  size_t payload_capacity = rtp_packet->FreeCapacity();
+  RTC_CHECK_GE(payload_capacity, kHevcNalHeaderSize);
+  uint8_t* buffer = rtp_packet->AllocatePayload(payload_capacity);
+
+  PacketUnit* packet = &packets_.front();
+  RTC_CHECK(packet->first_fragment);
+  uint8_t payload_hdr_h = packet->header >> 8;
+  uint8_t payload_hdr_l = packet->header & 0xFF;
+  uint8_t layer_id_h = payload_hdr_h & kHevcLayerIDHMask;
+
+  payload_hdr_h =
+      (payload_hdr_h & kHevcTypeMaskN) | (kHevcAp << 1) | layer_id_h;
+
+  buffer[0] = payload_hdr_h;
+  buffer[1] = payload_hdr_l;
+  int index = kHevcNalHeaderSize;
+  bool is_last_fragment = packet->last_fragment;
+  while (packet->aggregated) {
+    // Add NAL unit length field.
+    rtc::ArrayView<const uint8_t> fragment = packet->source_fragment;
+    ByteWriter<uint16_t>::WriteBigEndian(&buffer[index], fragment.size());
+    index += kHevcLengthFieldSize;
+    // Add NAL unit.
+    memcpy(&buffer[index], fragment.data(), fragment.size());
+    index += fragment.size();
+    packets_.pop();
+    input_fragments_.pop_front();
+    if (is_last_fragment)
+      break;
+    packet = &packets_.front();
+    is_last_fragment = packet->last_fragment;
+  }
+  RTC_CHECK(is_last_fragment);
+  rtp_packet->SetPayloadSize(index);
+}
+
+void RtpPacketizerH265::NextFragmentPacket(RtpPacketToSend* rtp_packet) {
+  PacketUnit* packet = &packets_.front();
+  // NAL unit fragmented over multiple packets (FU).
+  // We do not send original NALU header, so it will be replaced by the
+  // PayloadHdr of the first packet.
+  uint8_t payload_hdr_h =
+      packet->header >> 8;  // 1-bit F, 6-bit type, 1-bit layerID highest-bit
+  uint8_t payload_hdr_l = packet->header & 0xFF;
+  uint8_t layer_id_h = payload_hdr_h & kHevcLayerIDHMask;
+  uint8_t fu_header = 0;
+  // S | E |6 bit type.
+  fu_header |= (packet->first_fragment ? kHevcSBit : 0);
+  fu_header |= (packet->last_fragment ? kHevcEBit : 0);
+  uint8_t type = (payload_hdr_h & kHevcTypeMask) >> 1;
+  fu_header |= type;
+  // Now update payload_hdr_h with FU type.
+  payload_hdr_h =
+      (payload_hdr_h & kHevcTypeMaskN) | (kHevcFu << 1) | layer_id_h;
+  rtc::ArrayView<const uint8_t> fragment = packet->source_fragment;
+  uint8_t* buffer = rtp_packet->AllocatePayload(
+      kHevcFuHeaderSize + kHevcNalHeaderSize + fragment.size());
+  buffer[0] = payload_hdr_h;
+  buffer[1] = payload_hdr_l;
+  buffer[2] = fu_header;
+
+  if (packet->last_fragment) {
+    memcpy(buffer + kHevcFuHeaderSize + kHevcNalHeaderSize, fragment.data(),
+           fragment.size());
+  } else {
+    memcpy(buffer + kHevcFuHeaderSize + kHevcNalHeaderSize, fragment.data(),
+           fragment.size());
+  }
+  packets_.pop();
+}
+
+absl::optional<VideoRtpDepacketizer::ParsedRtpPayload> VideoRtpDepacketizerH265::Parse(
+                                rtc::CopyOnWriteBuffer rtp_payload) {
+  size_t payload_data_length = rtp_payload.size();
+  if (payload_data_length == 0) {
+    RTC_LOG(LS_ERROR) << "Empty payload.";
+    return absl::nullopt;
+  }
+
+  ParsedRtpPayload parsed_payload;
+
+  uint8_t* payload_data = rtp_payload.data();
+
+  offset_ = 0;
+  length_ = payload_data_length;
+  modified_buffer_.reset();
+
+  uint8_t nal_type = (payload_data[0] & kHevcTypeMask) >> 1;
+  parsed_payload.video_header
+      .video_type_header.emplace<RTPVideoHeaderH265>();
+
+  if (nal_type == H265::NaluType::kFU) {
+    // Fragmented NAL units (FU-A).
+    if (!ParseFuNalu(&parsed_payload, payload_data))
+      return absl::nullopt;
+  } else {
+    // We handle STAP-A and single NALU's the same way here. The jitter buffer
+    // will depacketize the STAP-A into NAL units later.
+    // TODO(sprang): Parse STAP-A offsets here and store in fragmentation vec.
+    if (!ProcessApOrSingleNalu(&parsed_payload, payload_data))
+      return absl::nullopt;
+  }
+
+  const uint8_t* payload =
+      modified_buffer_ ? modified_buffer_->data() : payload_data;
+
+  parsed_payload.video_payload = { payload + offset_, length_ };
+  return parsed_payload;
+}
+
+bool VideoRtpDepacketizerH265::ProcessApOrSingleNalu(
+    ParsedRtpPayload* parsed_payload,
+    const uint8_t* payload_data) {
+  parsed_payload->video_header.width = 0;
+  parsed_payload->video_header.height = 0;
+  parsed_payload->video_header.codec = kVideoCodecH265;
+  parsed_payload->video_header.is_first_packet_in_frame = true;
+  auto& h265_header = absl::get<RTPVideoHeaderH265>(
+      parsed_payload->video_header.video_type_header);
+
+  const uint8_t* nalu_start = payload_data + kHevcNalHeaderSize;
+  const size_t nalu_length = length_ - kHevcNalHeaderSize;
+  uint8_t nal_type = (payload_data[0] & kHevcTypeMask) >> 1;
+  std::vector<size_t> nalu_start_offsets;
+  if (nal_type == H265::NaluType::kAP) {
+    // Skip the StapA header (StapA NAL type + length).
+    if (length_ <= kHevcApHeaderSize) {
+      RTC_LOG(LS_ERROR) << "AP header truncated.";
+      return false;
+    }
+
+    if (!ParseApStartOffsets(nalu_start, nalu_length, &nalu_start_offsets)) {
+      RTC_LOG(LS_ERROR) << "AP packet with incorrect NALU packet lengths.";
+      return false;
+    }
+
+    h265_header.packetization_type = kH265AP;
+    // nal_type = (payload_data[kHevcApHeaderSize] & kHevcTypeMask) >> 1;
+  } else {
+    h265_header.packetization_type = kH265SingleNalu;
+    nalu_start_offsets.push_back(0);
+  }
+  h265_header.nalu_type = nal_type;
+  parsed_payload->video_header.frame_type = VideoFrameType::kVideoFrameDelta;
+
+  nalu_start_offsets.push_back(length_ + kHevcLengthFieldSize);  // End offset.
+  for (size_t i = 0; i < nalu_start_offsets.size() - 1; ++i) {
+    size_t start_offset = nalu_start_offsets[i];
+    // End offset is actually start offset for next unit, excluding length field
+    // so remove that from this units length.
+    size_t end_offset = nalu_start_offsets[i + 1] - kHevcLengthFieldSize;
+    if (end_offset - start_offset < kHevcNalHeaderSize) {  // Same as H.264.
+      RTC_LOG(LS_ERROR) << "AP packet too short";
+      return false;
+    }
+
+    H265NaluInfo nalu;
+    nalu.type = (payload_data[start_offset] & kHevcTypeMask) >> 1;
+    nalu.vps_id = -1;
+    nalu.sps_id = -1;
+    nalu.pps_id = -1;
+    start_offset += kHevcNalHeaderSize;
+    switch (nalu.type) {
+      case H265::NaluType::kVps: {
+        absl::optional<H265VpsParser::VpsState> vps = H265VpsParser::ParseVps(
+            &payload_data[start_offset], end_offset - start_offset);
+        if (vps) {
+          nalu.vps_id = vps->id;
+        } else {
+          RTC_LOG(LS_WARNING) << "Failed to parse VPS id from VPS slice.";
+        }
+        break;
+      }
+      case H265::NaluType::kSps: {
+        // Check if VUI is present in SPS and if it needs to be modified to
+        // avoid excessive decoder latency.
+
+        // Copy any previous data first (likely just the first header).
+        std::unique_ptr<rtc::Buffer> output_buffer(new rtc::Buffer());
+        if (start_offset)
+          output_buffer->AppendData(payload_data, start_offset);
+
+        absl::optional<H265SpsParser::SpsState> sps = H265SpsParser::ParseSps(
+            &payload_data[start_offset], end_offset - start_offset);
+
+        if (sps) {
+          parsed_payload->video_header.width = sps->width;
+          parsed_payload->video_header.height = sps->height;
+          nalu.sps_id = sps->id;
+          nalu.vps_id = sps->vps_id;
+        } else {
+          RTC_LOG(LS_WARNING)
+              << "Failed to parse SPS and VPS id from SPS slice.";
+        }
+        parsed_payload->video_header.frame_type = VideoFrameType::kVideoFrameKey;
+        break;
+      }
+      case H265::NaluType::kPps: {
+        uint32_t pps_id;
+        uint32_t sps_id;
+        if (H265PpsParser::ParsePpsIds(&payload_data[start_offset],
+                                       end_offset - start_offset, &pps_id,
+                                       &sps_id)) {
+          nalu.pps_id = pps_id;
+          nalu.sps_id = sps_id;
+        } else {
+          RTC_LOG(LS_WARNING)
+              << "Failed to parse PPS id and SPS id from PPS slice.";
+        }
+        break;
+      }
+      case H265::NaluType::kIdrWRadl:
+      case H265::NaluType::kIdrNLp:
+      case H265::NaluType::kCra:
+        parsed_payload->video_header.frame_type = VideoFrameType::kVideoFrameKey;
+        ABSL_FALLTHROUGH_INTENDED;
+      case H265::NaluType::kTrailN:
+      case H265::NaluType::kTrailR: {
+        absl::optional<uint32_t> pps_id =
+            H265PpsParser::ParsePpsIdFromSliceSegmentLayerRbsp(
+                &payload_data[start_offset], end_offset - start_offset,
+                nalu.type);
+        if (pps_id) {
+          nalu.pps_id = *pps_id;
+        } else {
+          RTC_LOG(LS_WARNING) << "Failed to parse PPS id from slice of type: "
+                              << static_cast<int>(nalu.type);
+        }
+        break;
+      }
+      // Slices below don't contain SPS or PPS ids.
+      case H265::NaluType::kAud:
+      case H265::NaluType::kTsaN:
+      case H265::NaluType::kTsaR:
+      case H265::NaluType::kStsaN:
+      case H265::NaluType::kStsaR:
+      case H265::NaluType::kRadlN:
+      case H265::NaluType::kRadlR:
+      case H265::NaluType::kBlaWLp:
+      case H265::NaluType::kBlaWRadl:
+      case H265::NaluType::kPrefixSei:
+      case H265::NaluType::kSuffixSei:
+        break;
+      case H265::NaluType::kAP:
+      case H265::NaluType::kFU:
+        RTC_LOG(LS_WARNING) << "Unexpected AP or FU received.";
+        return false;
+    }
+
+    if (h265_header.nalus_length == kMaxNalusPerPacket) {
+      RTC_LOG(LS_WARNING)
+          << "Received packet containing more than " << kMaxNalusPerPacket
+          << " NAL units. Will not keep track sps and pps ids for all of them.";
+    } else {
+      h265_header.nalus[h265_header.nalus_length++] = nalu;
+    }
+  }
+  return true;
+}
+
+bool VideoRtpDepacketizerH265::ParseFuNalu(
+    ParsedRtpPayload* parsed_payload,
+    const uint8_t* payload_data) {
+  if (length_ < kHevcFuHeaderSize + kHevcNalHeaderSize) {
+    RTC_LOG(LS_ERROR) << "FU NAL units truncated.";
+    return false;
+  }
+  uint8_t f = payload_data[0] & kHevcFBit;
+  uint8_t layer_id_h = payload_data[0] & kHevcLayerIDHMask;
+  uint8_t layer_id_l_unshifted = payload_data[1] & kHevcLayerIDLMask;
+  uint8_t tid = payload_data[1] & kHevcTIDMask;
+
+  uint8_t original_nal_type = payload_data[2] & kHevcTypeMaskInFuHeader;
+  bool first_fragment = payload_data[2] & kHevcSBit;
+  H265NaluInfo nalu;
+  nalu.type = original_nal_type;
+  nalu.vps_id = -1;
+  nalu.sps_id = -1;
+  nalu.pps_id = -1;
+  if (first_fragment) {
+    offset_ = 1;
+    length_ -= 1;
+    absl::optional<uint32_t> pps_id =
+        H265PpsParser::ParsePpsIdFromSliceSegmentLayerRbsp(
+            payload_data + kHevcNalHeaderSize + kHevcFuHeaderSize,
+            length_ - kHevcFuHeaderSize, nalu.type);
+    if (pps_id) {
+      nalu.pps_id = *pps_id;
+    } else {
+      RTC_LOG(LS_WARNING)
+          << "Failed to parse PPS from first fragment of FU NAL "
+             "unit with original type: "
+          << static_cast<int>(nalu.type);
+    }
+    uint8_t* payload = const_cast<uint8_t*>(payload_data + offset_);
+    payload[0] = f | original_nal_type << 1 | layer_id_h;
+    payload[1] = layer_id_l_unshifted | tid;
+  } else {
+    offset_ = kHevcNalHeaderSize + kHevcFuHeaderSize;
+    length_ -= (kHevcNalHeaderSize + kHevcFuHeaderSize);
+  }
+
+  if (original_nal_type == H265::NaluType::kIdrWRadl
+      || original_nal_type == H265::NaluType::kIdrNLp
+      || original_nal_type == H265::NaluType::kCra) {
+    parsed_payload->video_header.frame_type = VideoFrameType::kVideoFrameKey;
+  } else {
+    parsed_payload->video_header.frame_type = VideoFrameType::kVideoFrameDelta;
+  }
+  parsed_payload->video_header.width = 0;
+  parsed_payload->video_header.height = 0;
+  parsed_payload->video_header.codec = kVideoCodecH265;
+  parsed_payload->video_header.is_first_packet_in_frame = first_fragment;
+  auto& h265_header = absl::get<RTPVideoHeaderH265>(
+      parsed_payload->video_header.video_type_header);
+  h265_header.packetization_type = kH265FU;
+  h265_header.nalu_type = original_nal_type;
+  if (first_fragment) {
+    h265_header.nalus[h265_header.nalus_length] = nalu;
+    h265_header.nalus_length = 1;
+  }
+  return true;
+}
+
+}  // namespace webrtc
\ No newline at end of file
diff --git a/modules/rtp_rtcp/source/rtp_format_h265.h b/modules/rtp_rtcp/source/rtp_format_h265.h
new file mode 100644
index 0000000000..86e26b79b5
--- /dev/null
+++ b/modules/rtp_rtcp/source/rtp_format_h265.h
@@ -0,0 +1,129 @@
+/*
+ *  Intel License
+ * See https://01.org/open-webrtc-toolkit
+ * This is released under Apache License 2.0 and it is free for both academic and commercial use.
+ */
+
+#ifndef WEBRTC_MODULES_RTP_RTCP_SOURCE_RTP_FORMAT_H265_H_
+#define WEBRTC_MODULES_RTP_RTCP_SOURCE_RTP_FORMAT_H265_H_
+
+#include <queue>
+#include <string>
+#include "api/array_view.h"
+#include "modules/include/module_common_types.h"
+#include "modules/rtp_rtcp/source/rtp_format.h"
+#include "modules/rtp_rtcp/source/rtp_packet_to_send.h"
+#include "modules/rtp_rtcp/source/rtp_format.h"
+#include "modules/rtp_rtcp/source/video_rtp_depacketizer.h"
+#include "modules/video_coding/codecs/h265/include/h265_globals.h"
+#include "rtc_base/buffer.h"
+#include "rtc_base/constructor_magic.h"
+
+namespace webrtc {
+
+class RtpPacketizerH265 : public RtpPacketizer {
+ public:
+  // Initialize with payload from encoder.
+  // The payload_data must be exactly one encoded H.265 frame.
+  RtpPacketizerH265(rtc::ArrayView<const uint8_t> payload,
+                    PayloadSizeLimits limits,
+                    H265PacketizationMode packetization_mode);
+
+   ~RtpPacketizerH265() override;
+
+  size_t NumPackets() const override;
+
+  // Get the next payload with H.265 payload header.
+  // buffer is a pointer to where the output will be written.
+  // bytes_to_send is an output variable that will contain number of bytes
+  // written to buffer. The parameter last_packet is true for the last packet of
+  // the frame, false otherwise (i.e., call the function again to get the
+  // next packet).
+  // Returns true on success or false if there was no payload to packetize.
+  bool NextPacket(RtpPacketToSend* rtp_packet) override;
+
+ private:
+  struct Packet {
+    Packet(size_t offset,
+           size_t size,
+           bool first_fragment,
+           bool last_fragment,
+           bool aggregated,
+           uint16_t header)
+        : offset(offset),
+          size(size),
+          first_fragment(first_fragment),
+          last_fragment(last_fragment),
+          aggregated(aggregated),
+          header(header) {}
+
+    size_t offset;
+    size_t size;
+    bool first_fragment;
+    bool last_fragment;
+    bool aggregated;
+    uint16_t header;  // Different from H264
+  };
+  struct Fragment {
+    Fragment(const uint8_t* buffer, size_t length);
+    explicit Fragment(const Fragment& fragment);
+    const uint8_t* buffer = nullptr;
+    size_t length = 0;
+    std::unique_ptr<rtc::Buffer> tmp_buffer;
+  };
+  struct PacketUnit {
+    PacketUnit(rtc::ArrayView<const uint8_t> source_fragment,
+               bool first_fragment,
+               bool last_fragment,
+               bool aggregated,
+               uint16_t header)
+        : source_fragment(source_fragment),
+          first_fragment(first_fragment),
+          last_fragment(last_fragment),
+          aggregated(aggregated),
+          header(header) {}
+
+    rtc::ArrayView<const uint8_t> source_fragment;
+    bool first_fragment;
+    bool last_fragment;
+    bool aggregated;
+    uint16_t header;
+  };
+  typedef std::queue<Packet> PacketQueue;
+  std::deque<rtc::ArrayView<const uint8_t>> input_fragments_;
+  std::queue<PacketUnit> packets_;
+
+  bool GeneratePackets(H265PacketizationMode packetization_mode);
+  bool PacketizeFu(size_t fragment_index);
+  int PacketizeAp(size_t fragment_index);
+  bool PacketizeSingleNalu(size_t fragment_index);
+
+  void NextAggregatePacket(RtpPacketToSend* rtp_packet, bool last);
+  void NextFragmentPacket(RtpPacketToSend* rtp_packet);
+
+  const PayloadSizeLimits limits_;
+  size_t num_packets_left_;
+
+  RTC_DISALLOW_COPY_AND_ASSIGN(RtpPacketizerH265);
+};
+
+// Depacketizer for H.265.
+class VideoRtpDepacketizerH265 : public VideoRtpDepacketizer {
+ public:
+  virtual ~VideoRtpDepacketizerH265() {}
+
+  absl::optional<ParsedRtpPayload> Parse(
+             rtc::CopyOnWriteBuffer rtp_payload) override;
+
+ private:
+  bool ParseFuNalu(ParsedRtpPayload* parsed_payload,
+                   const uint8_t* payload_data);
+  bool ProcessApOrSingleNalu(ParsedRtpPayload* parsed_payload,
+                             const uint8_t* payload_data);
+
+  size_t offset_;
+  size_t length_;
+  std::unique_ptr<rtc::Buffer> modified_buffer_;
+};
+}  // namespace webrtc
+#endif  // WEBRTC_MODULES_RTP_RTCP_SOURCE_RTP_FORMAT_H265_H_
\ No newline at end of file
diff --git a/modules/rtp_rtcp/source/rtp_sender_video.cc b/modules/rtp_rtcp/source/rtp_sender_video.cc
index 8ce1eed913..6e0eb76cb1 100644
--- a/modules/rtp_rtcp/source/rtp_sender_video.cc
+++ b/modules/rtp_rtcp/source/rtp_sender_video.cc
@@ -749,6 +749,7 @@ uint8_t RTPSenderVideo::GetTemporalId(const RTPVideoHeader& header) {
       return vp9.temporal_idx;
     }
     uint8_t operator()(const RTPVideoHeaderH264&) { return kNoTemporalIdx; }
+    uint8_t operator()(const RTPVideoHeaderH265&) { return kNoTemporalIdx; }
     uint8_t operator()(const RTPVideoHeaderLegacyGeneric&) {
       return kNoTemporalIdx;
     }
diff --git a/modules/rtp_rtcp/source/rtp_video_header.h b/modules/rtp_rtcp/source/rtp_video_header.h
index ca3415587d..b73ccdb4c2 100644
--- a/modules/rtp_rtcp/source/rtp_video_header.h
+++ b/modules/rtp_rtcp/source/rtp_video_header.h
@@ -24,6 +24,7 @@
 #include "api/video/video_rotation.h"
 #include "api/video/video_timing.h"
 #include "modules/video_coding/codecs/h264/include/h264_globals.h"
+#include "modules/video_coding/codecs/h265/include/h265_globals.h"
 #include "modules/video_coding/codecs/vp8/include/vp8_globals.h"
 #include "modules/video_coding/codecs/vp9/include/vp9_globals.h"
 
@@ -39,6 +40,7 @@ using RTPVideoTypeHeader = absl::variant<absl::monostate,
                                          RTPVideoHeaderVP8,
                                          RTPVideoHeaderVP9,
                                          RTPVideoHeaderH264,
+                                         RTPVideoHeaderH265,
                                          RTPVideoHeaderLegacyGeneric>;
 
 struct RTPVideoHeader {
diff --git a/modules/third_party/portaudio/BUILD.gn b/modules/third_party/portaudio/BUILD.gn
index c49c544e9d..a43f8a9e6a 100644
--- a/modules/third_party/portaudio/BUILD.gn
+++ b/modules/third_party/portaudio/BUILD.gn
@@ -10,6 +10,7 @@ import("../../../webrtc.gni")
 
 rtc_library("mac_portaudio") {
   visibility = [ "../../audio_device:*" ]
+  cflags = [ "-Wno-deprecated-declarations" ]
   sources = [
     "pa_memorybarrier.h",
     "pa_ringbuffer.c",
diff --git a/modules/video_coding/BUILD.gn b/modules/video_coding/BUILD.gn
index bf8a4d620c..f68ba7bcb7 100644
--- a/modules/video_coding/BUILD.gn
+++ b/modules/video_coding/BUILD.gn
@@ -15,6 +15,12 @@ rtc_library("encoded_frame") {
     "encoded_frame.cc",
     "encoded_frame.h",
   ]
+
+  sources += [
+    "h265_vps_sps_pps_tracker.cc",
+    "h265_vps_sps_pps_tracker.h",
+  ]
+
   deps = [
     ":codec_globals_headers",
     ":video_codec_interface",
diff --git a/modules/video_coding/codecs/h265/include/h265_globals.h b/modules/video_coding/codecs/h265/include/h265_globals.h
new file mode 100644
index 0000000000..ad511d11d5
--- /dev/null
+++ b/modules/video_coding/codecs/h265/include/h265_globals.h
@@ -0,0 +1,62 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+// This file contains codec dependent definitions that are needed in
+// order to compile the WebRTC codebase, even if this codec is not used.
+
+#ifndef MODULES_VIDEO_CODING_CODECS_H265_INCLUDE_H265_GLOBALS_H_
+#define MODULES_VIDEO_CODING_CODECS_H265_INCLUDE_H265_GLOBALS_H_
+
+#ifndef DISABLE_H265
+
+#include "modules/video_coding/codecs/h264/include/h264_globals.h"
+
+namespace webrtc {
+
+// The packetization types that we support: single, aggregated, and fragmented.
+enum H265PacketizationTypes {
+  kH265SingleNalu,  // This packet contains a single NAL unit.
+  kH265AP,          // This packet contains aggregation Packet.
+                    // If this packet has an associated NAL unit type,
+                    // it'll be for the first such aggregated packet.
+  kH265FU,          // This packet contains a FU (fragmentation
+                    // unit) packet, meaning it is a part of a frame
+                    // that was too large to fit into a single packet.
+};
+
+struct H265NaluInfo {
+  uint8_t type;
+  int vps_id;
+  int sps_id;
+  int pps_id;
+};
+
+enum class H265PacketizationMode {
+  NonInterleaved = 0,  // Mode 1 - STAP-A, FU-A is allowed
+  SingleNalUnit        // Mode 0 - only single NALU allowed
+};
+
+struct RTPVideoHeaderH265 {
+  // The NAL unit type. If this is a header for a fragmented packet, it's the
+  // NAL unit type of the original data. If this is the header for an aggregated
+  // packet, it's the NAL unit type of the first NAL unit in the packet.
+  uint8_t nalu_type;
+  H265PacketizationTypes packetization_type;
+  H265NaluInfo nalus[kMaxNalusPerPacket];
+  size_t nalus_length;
+  // The packetization type of this buffer - single, aggregated or fragmented.
+  H265PacketizationMode packetization_mode;
+};
+
+}  // namespace webrtc
+
+#endif
+
+#endif  // MODULES_VIDEO_CODING_CODECS_H265_INCLUDE_H265_GLOBALS_H_
\ No newline at end of file
diff --git a/modules/video_coding/encoded_frame.cc b/modules/video_coding/encoded_frame.cc
index 3de62da9f5..b1183a70c5 100644
--- a/modules/video_coding/encoded_frame.cc
+++ b/modules/video_coding/encoded_frame.cc
@@ -137,6 +137,10 @@ void VCMEncodedFrame::CopyCodecSpecific(const RTPVideoHeader* header) {
         _codecSpecificInfo.codecType = kVideoCodecH264;
         break;
       }
+      case kVideoCodecH265: {
+        _codecSpecificInfo.codecType = kVideoCodecH265;
+        break;
+      }
       default: {
         _codecSpecificInfo.codecType = kVideoCodecGeneric;
         break;
diff --git a/modules/video_coding/h265_vps_sps_pps_tracker.cc b/modules/video_coding/h265_vps_sps_pps_tracker.cc
new file mode 100644
index 0000000000..ce77cebfc4
--- /dev/null
+++ b/modules/video_coding/h265_vps_sps_pps_tracker.cc
@@ -0,0 +1,312 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/video_coding/h265_vps_sps_pps_tracker.h"
+
+#include <string>
+#include <utility>
+
+#include "common_video/h264/h264_common.h"
+#include "common_video/h265/h265_common.h"
+#include "common_video/h265/h265_pps_parser.h"
+#include "common_video/h265/h265_sps_parser.h"
+#include "common_video/h265/h265_vps_parser.h"
+#include "modules/video_coding/codecs/h264/include/h264_globals.h"
+#include "modules/video_coding/codecs/h265/include/h265_globals.h"
+#include "modules/video_coding/frame_object.h"
+#include "modules/video_coding/packet_buffer.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/logging.h"
+
+namespace webrtc {
+namespace video_coding {
+
+namespace {
+const uint8_t start_code_h265[] = {0, 0, 0, 1};
+}  // namespace
+
+H265VpsSpsPpsTracker::FixedBitstream H265VpsSpsPpsTracker::CopyAndFixBitstream(rtc::ArrayView<const uint8_t> bitstream,
+                                   RTPVideoHeader* video_header_pointer) {
+  const uint8_t* data = bitstream.data();
+  const size_t data_size = bitstream.size();
+  RTPVideoHeader& video_header = *video_header_pointer;
+  RTC_DCHECK(video_header.codec == kVideoCodecH264);
+
+  auto& h265_header =
+      absl::get<RTPVideoHeaderH265>(video_header.video_type_header);
+
+  bool append_vps_sps_pps = false;
+  auto vps = vps_data_.end();
+  auto sps = sps_data_.end();
+  auto pps = pps_data_.end();
+
+  for (size_t i = 0; i < h265_header.nalus_length; ++i) {
+    const H265NaluInfo& nalu = h265_header.nalus[i];
+    switch (nalu.type) {
+      case H265::NaluType::kVps: {
+        vps_data_[nalu.vps_id].size = 0;
+        break;
+      }
+      case H265::NaluType::kSps: {
+        sps_data_[nalu.sps_id].vps_id = nalu.vps_id;
+        sps_data_[nalu.sps_id].width = video_header.width;
+        sps_data_[nalu.sps_id].height = video_header.height;
+        break;
+      }
+      case H265::NaluType::kPps: {
+        pps_data_[nalu.pps_id].sps_id = nalu.sps_id;
+        break;
+      }
+      case H265::NaluType::kIdrWRadl:
+      case H265::NaluType::kIdrNLp:
+      case H265::NaluType::kCra: {
+        // If this is the first packet of an IDR, make sure we have the required
+        // SPS/PPS and also calculate how much extra space we need in the buffer
+        // to prepend the SPS/PPS to the bitstream with start codes.
+        if (video_header.is_first_packet_in_frame) {
+          if (nalu.pps_id == -1) {
+            RTC_LOG(LS_WARNING) << "No PPS id in IDR nalu.";
+            return {kRequestKeyframe};
+          }
+
+          pps = pps_data_.find(nalu.pps_id);
+          if (pps == pps_data_.end()) {
+            RTC_LOG(LS_WARNING)
+                << "No PPS with id " << nalu.pps_id << " received";
+            return {kRequestKeyframe};
+          }
+
+          sps = sps_data_.find(pps->second.sps_id);
+          if (sps == sps_data_.end()) {
+            RTC_LOG(LS_WARNING)
+                << "No SPS with id << " << pps->second.sps_id << " received";
+            return {kRequestKeyframe};
+          }
+
+          vps = vps_data_.find(sps->second.vps_id);
+          if (vps == vps_data_.end()) {
+            RTC_LOG(LS_WARNING)
+                << "No VPS with id " << sps->second.vps_id << " received";
+            return {kRequestKeyframe};
+          }
+
+          // Since the first packet of every keyframe should have its width and
+          // height set we set it here in the case of it being supplied out of
+          // band.
+          video_header.width = sps->second.width;
+          video_header.height = sps->second.height;
+
+          // If the VPS/SPS/PPS was supplied out of band then we will have saved
+          // the actual bitstream in |data|.
+          // This branch is not verified.
+          if (vps->second.data && sps->second.data && pps->second.data) {
+            RTC_DCHECK_GT(vps->second.size, 0);
+            RTC_DCHECK_GT(sps->second.size, 0);
+            RTC_DCHECK_GT(pps->second.size, 0);
+            append_vps_sps_pps = true;
+          }
+        }
+        break;
+      }
+      default:
+        break;
+    }
+  }
+
+  RTC_CHECK(!append_vps_sps_pps ||
+            (sps != sps_data_.end() && pps != pps_data_.end()));
+
+  // Calculate how much space we need for the rest of the bitstream.
+  size_t required_size = 0;
+
+  if (append_vps_sps_pps) {
+    required_size += vps->second.size + sizeof(start_code_h265);
+    required_size += sps->second.size + sizeof(start_code_h265);
+    required_size += pps->second.size + sizeof(start_code_h265);
+  }
+
+  if (h265_header.packetization_type == kH265AP) {
+    const uint8_t* nalu_ptr = data + 1;
+    while (nalu_ptr < data + data_size) {
+      RTC_DCHECK(video_header.is_first_packet_in_frame);
+      required_size += sizeof(start_code_h265);
+
+      // The first two bytes describe the length of a segment.
+      uint16_t segment_length = nalu_ptr[0] << 8 | nalu_ptr[1];
+      nalu_ptr += 2;
+
+      required_size += segment_length;
+      nalu_ptr += segment_length;
+    }
+  } else {
+    if (video_header.is_first_packet_in_frame)
+      required_size += sizeof(start_code_h265);
+    required_size += data_size;
+  }
+
+  // Then we copy to the new buffer.
+  FixedBitstream fixed;
+  fixed.bitstream.EnsureCapacity(required_size);
+
+  if (append_vps_sps_pps) {
+    // Insert VPS.
+    fixed.bitstream.AppendData(start_code_h265);
+    fixed.bitstream.AppendData(vps->second.data.get(), vps->second.size);
+
+    // Insert SPS.
+    fixed.bitstream.AppendData(start_code_h265);
+    fixed.bitstream.AppendData(sps->second.data.get(), sps->second.size);
+
+    // Insert PPS.
+    fixed.bitstream.AppendData(start_code_h265);
+    fixed.bitstream.AppendData(pps->second.data.get(), pps->second.size);
+
+    // Update codec header to reflect the newly added SPS and PPS.
+    H265NaluInfo vps_info;
+    vps_info.type = H265::NaluType::kVps;
+    vps_info.vps_id = vps->first;
+    vps_info.sps_id = -1;
+    vps_info.pps_id = -1;
+    H265NaluInfo sps_info;
+    sps_info.type = H265::NaluType::kSps;
+    sps_info.vps_id = vps->first;
+    sps_info.sps_id = sps->first;
+    sps_info.pps_id = -1;
+    H265NaluInfo pps_info;
+    pps_info.type = H265::NaluType::kPps;
+    pps_info.vps_id = vps->first;
+    pps_info.sps_id = sps->first;
+    pps_info.pps_id = pps->first;
+    if (h265_header.nalus_length + 2 <= kMaxNalusPerPacket) {
+      h265_header.nalus[h265_header.nalus_length++] = vps_info;
+      h265_header.nalus[h265_header.nalus_length++] = sps_info;
+      h265_header.nalus[h265_header.nalus_length++] = pps_info;
+    } else {
+      RTC_LOG(LS_WARNING) << "Not enough space in H.265 codec header to insert "
+                             "SPS/PPS provided out-of-band.";
+    }
+  }
+
+  // Copy the rest of the bitstream and insert start codes.
+  if (h265_header.packetization_type == kH265AP) {
+    const uint8_t* nalu_ptr = data + 1;
+    while (nalu_ptr < data + data_size) {
+      fixed.bitstream.AppendData(start_code_h265);
+
+      // The first two bytes describe the length of a segment.
+      uint16_t segment_length = nalu_ptr[0] << 8 | nalu_ptr[1];
+      nalu_ptr += 2;
+
+      size_t copy_end = nalu_ptr - data + segment_length;
+      if (copy_end > data_size) {
+        return {kDrop};
+      }
+
+      fixed.bitstream.AppendData(nalu_ptr, segment_length);
+      nalu_ptr += segment_length;
+    }
+  } else {
+    if (video_header.is_first_packet_in_frame) {
+      fixed.bitstream.AppendData(start_code_h265);
+    }
+    fixed.bitstream.AppendData(bitstream.data(), bitstream.size());
+  }
+
+  fixed.action = kInsert;
+  return fixed;
+}
+
+void H265VpsSpsPpsTracker::InsertVpsSpsPpsNalus(
+    const std::vector<uint8_t>& vps,
+    const std::vector<uint8_t>& sps,
+    const std::vector<uint8_t>& pps) {
+  constexpr size_t kNaluHeaderOffset = 1;
+  if (vps.size() < kNaluHeaderOffset) {
+    RTC_LOG(LS_WARNING) << "VPS size  " << vps.size() << " is smaller than "
+                        << kNaluHeaderOffset;
+    return;
+  }
+  if ((vps[0] & 0x7e) >> 1 != H265::NaluType::kSps) {
+    RTC_LOG(LS_WARNING) << "SPS Nalu header missing";
+    return;
+  }
+  if (sps.size() < kNaluHeaderOffset) {
+    RTC_LOG(LS_WARNING) << "SPS size  " << sps.size() << " is smaller than "
+                        << kNaluHeaderOffset;
+    return;
+  }
+  if ((sps[0] & 0x7e) >> 1 != H265::NaluType::kSps) {
+    RTC_LOG(LS_WARNING) << "SPS Nalu header missing";
+    return;
+  }
+  if (pps.size() < kNaluHeaderOffset) {
+    RTC_LOG(LS_WARNING) << "PPS size  " << pps.size() << " is smaller than "
+                        << kNaluHeaderOffset;
+    return;
+  }
+  if ((pps[0] & 0x7e) >> 1 != H265::NaluType::kPps) {
+    RTC_LOG(LS_WARNING) << "SPS Nalu header missing";
+    return;
+  }
+  absl::optional<H265VpsParser::VpsState> parsed_vps = H265VpsParser::ParseVps(
+      vps.data() + kNaluHeaderOffset, vps.size() - kNaluHeaderOffset);
+  absl::optional<H265SpsParser::SpsState> parsed_sps = H265SpsParser::ParseSps(
+      sps.data() + kNaluHeaderOffset, sps.size() - kNaluHeaderOffset);
+  absl::optional<H265PpsParser::PpsState> parsed_pps = H265PpsParser::ParsePps(
+      pps.data() + kNaluHeaderOffset, pps.size() - kNaluHeaderOffset);
+
+  if (!parsed_vps) {
+    RTC_LOG(LS_WARNING) << "Failed to parse VPS.";
+  }
+
+  if (!parsed_sps) {
+    RTC_LOG(LS_WARNING) << "Failed to parse SPS.";
+  }
+
+  if (!parsed_pps) {
+    RTC_LOG(LS_WARNING) << "Failed to parse PPS.";
+  }
+
+  if (!parsed_vps || !parsed_pps || !parsed_sps) {
+    return;
+  }
+
+  VpsInfo vps_info;
+  vps_info.size = vps.size();
+  uint8_t* vps_data = new uint8_t[vps_info.size];
+  memcpy(vps_data, vps.data(), vps_info.size);
+  vps_info.data.reset(vps_data);
+  vps_data_[parsed_vps->id] = std::move(vps_info);
+
+  SpsInfo sps_info;
+  sps_info.size = sps.size();
+  sps_info.width = parsed_sps->width;
+  sps_info.height = parsed_sps->height;
+  sps_info.vps_id = parsed_sps->vps_id;
+  uint8_t* sps_data = new uint8_t[sps_info.size];
+  memcpy(sps_data, sps.data(), sps_info.size);
+  sps_info.data.reset(sps_data);
+  sps_data_[parsed_sps->id] = std::move(sps_info);
+
+  PpsInfo pps_info;
+  pps_info.size = pps.size();
+  pps_info.sps_id = parsed_pps->sps_id;
+  uint8_t* pps_data = new uint8_t[pps_info.size];
+  memcpy(pps_data, pps.data(), pps_info.size);
+  pps_info.data.reset(pps_data);
+  pps_data_[parsed_pps->id] = std::move(pps_info);
+
+  RTC_LOG(LS_INFO) << "Inserted SPS id " << parsed_sps->id << " and PPS id "
+                   << parsed_pps->id << " (referencing SPS "
+                   << parsed_pps->sps_id << ")";
+}
+
+}  // namespace video_coding
+}  // namespace webrtc
\ No newline at end of file
diff --git a/modules/video_coding/h265_vps_sps_pps_tracker.h b/modules/video_coding/h265_vps_sps_pps_tracker.h
new file mode 100644
index 0000000000..252403eaa1
--- /dev/null
+++ b/modules/video_coding/h265_vps_sps_pps_tracker.h
@@ -0,0 +1,74 @@
+/*
+ *  Copyright (c) 2018 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef MODULES_VIDEO_CODING_H265_VPS_SPS_PPS_TRACKER_H_
+#define MODULES_VIDEO_CODING_H265_VPS_SPS_PPS_TRACKER_H_
+
+#include <cstdint>
+#include <map>
+#include <memory>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/include/module_common_types.h"
+#include "modules/rtp_rtcp/source/rtp_video_header.h"
+#include "rtc_base/copy_on_write_buffer.h"
+
+namespace webrtc {
+
+class VCMPacket;
+
+namespace video_coding {
+
+class H265VpsSpsPpsTracker {
+ public:
+  enum PacketAction { kInsert, kDrop, kRequestKeyframe };
+  struct FixedBitstream {
+    PacketAction action;
+    rtc::CopyOnWriteBuffer bitstream;
+  };
+
+  // Returns fixed bitstream and modifies |video_header|.
+  FixedBitstream CopyAndFixBitstream(rtc::ArrayView<const uint8_t> bitstream,
+                                     RTPVideoHeader* video_header);
+
+  void InsertVpsSpsPpsNalus(const std::vector<uint8_t>& vps,
+                            const std::vector<uint8_t>& sps,
+                            const std::vector<uint8_t>& pps);
+
+ private:
+  struct VpsInfo {
+    size_t size = 0;
+    std::unique_ptr<uint8_t[]> data;
+  };
+
+  struct PpsInfo {
+    int sps_id = -1;
+    size_t size = 0;
+    std::unique_ptr<uint8_t[]> data;
+  };
+
+  struct SpsInfo {
+    int vps_id = -1;
+    size_t size = 0;
+    int width = -1;
+    int height = -1;
+    std::unique_ptr<uint8_t[]> data;
+  };
+
+  std::map<uint32_t, VpsInfo> vps_data_;
+  std::map<uint32_t, PpsInfo> pps_data_;
+  std::map<uint32_t, SpsInfo> sps_data_;
+};
+
+}  // namespace video_coding
+}  // namespace webrtc
+
+#endif  // MODULES_VIDEO_CODING_H264_SPS_PPS_TRACKER_H_
\ No newline at end of file
diff --git a/modules/video_coding/include/video_codec_interface.h b/modules/video_coding/include/video_codec_interface.h
index c7b116f4ae..6f58f72b9b 100644
--- a/modules/video_coding/include/video_codec_interface.h
+++ b/modules/video_coding/include/video_codec_interface.h
@@ -20,6 +20,7 @@
 #include "common_video/generic_frame_descriptor/generic_frame_info.h"
 #include "modules/include/module_common_types.h"
 #include "modules/video_coding/codecs/h264/include/h264_globals.h"
+#include "modules/video_coding/codecs/h265/include/h265_globals.h"
 #include "modules/video_coding/codecs/vp9/include/vp9_globals.h"
 #include "modules/video_coding/include/video_error_codes.h"
 #include "rtc_base/system/rtc_export.h"
@@ -92,10 +93,17 @@ struct CodecSpecificInfoH264 {
 };
 static_assert(std::is_pod<CodecSpecificInfoH264>::value, "");
 
+struct CodecSpecificInfoH265 {
+  H265PacketizationMode packetization_mode;
+  bool idr_frame;
+};
+// (check:tnoho)
+
 union CodecSpecificInfoUnion {
   CodecSpecificInfoVP8 VP8;
   CodecSpecificInfoVP9 VP9;
   CodecSpecificInfoH264 H264;
+  CodecSpecificInfoH265 H265;
 };
 static_assert(std::is_pod<CodecSpecificInfoUnion>::value, "");
 
diff --git a/modules/video_coding/jitter_buffer_common.h b/modules/video_coding/jitter_buffer_common.h
index 6ccfe39199..cd85127699 100644
--- a/modules/video_coding/jitter_buffer_common.h
+++ b/modules/video_coding/jitter_buffer_common.h
@@ -54,6 +54,7 @@ enum VCMFrameBufferStateEnum {
 };
 
 enum { kH264StartCodeLengthBytes = 4 };
+enum { kH265StartCodeLengthBytes = 4 };
 }  // namespace webrtc
 
 #endif  // MODULES_VIDEO_CODING_JITTER_BUFFER_COMMON_H_
diff --git a/modules/video_coding/packet.cc b/modules/video_coding/packet.cc
index 0c4a658b8f..cb7c7dc468 100644
--- a/modules/video_coding/packet.cc
+++ b/modules/video_coding/packet.cc
@@ -44,7 +44,7 @@ VCMPacket::VCMPacket(const uint8_t* ptr,
       markerBit(rtp_header.markerBit),
       timesNacked(-1),
       completeNALU(kNaluIncomplete),
-      insertStartCode(videoHeader.codec == kVideoCodecH264 &&
+      insertStartCode((videoHeader.codec == kVideoCodecH264 || videoHeader.codec == kVideoCodecH265) &&
                       videoHeader.is_first_packet_in_frame),
       video_header(videoHeader),
       packet_info(rtp_header, receive_time_ms) {
diff --git a/modules/video_coding/packet_buffer.cc b/modules/video_coding/packet_buffer.cc
index d2a2bcfb47..bc1f3b0c73 100644
--- a/modules/video_coding/packet_buffer.cc
+++ b/modules/video_coding/packet_buffer.cc
@@ -23,10 +23,12 @@
 #include "api/rtp_packet_info.h"
 #include "api/video/video_frame_type.h"
 #include "common_video/h264/h264_common.h"
+#include "common_video/h265/h265_common.h"
 #include "modules/rtp_rtcp/source/rtp_header_extensions.h"
 #include "modules/rtp_rtcp/source/rtp_packet_received.h"
 #include "modules/rtp_rtcp/source/rtp_video_header.h"
 #include "modules/video_coding/codecs/h264/include/h264_globals.h"
+#include "modules/video_coding/codecs/h265/include/h265_globals.h"
 #include "rtc_base/checks.h"
 #include "rtc_base/logging.h"
 #include "rtc_base/numerics/mod_ops.h"
@@ -275,12 +277,17 @@ std::vector<std::unique_ptr<PacketBuffer::Packet>> PacketBuffer::FindFrames(
       bool has_h264_pps = false;
       bool has_h264_idr = false;
       bool is_h264_keyframe = false;
+      bool is_h265 = buffer_[start_index]->codec() == kVideoCodecH265;
+      bool has_h265_sps = false;
+      bool has_h265_pps = false;
+      bool has_h265_idr = false;
+      bool is_h265_keyframe = false;
       int idr_width = -1;
       int idr_height = -1;
       while (true) {
         ++tested_packets;
 
-        if (!is_h264 && buffer_[start_index]->is_first_packet_in_frame())
+        if (!is_h264 && !is_h265 && buffer_[start_index]->is_first_packet_in_frame())
           break;
 
         if (is_h264) {
@@ -314,6 +321,27 @@ std::vector<std::unique_ptr<PacketBuffer::Packet>> PacketBuffer::FindFrames(
           }
         }
 
+        if (is_h265 && !is_h265_keyframe) {
+          const auto* h265_header = absl::get_if<RTPVideoHeaderH265>(
+              &buffer_[start_index]->video_header.video_type_header);
+          if (!h265_header || h265_header->nalus_length >= kMaxNalusPerPacket)
+            return found_frames;
+          for (size_t j = 0; j < h265_header->nalus_length; ++j) {
+            if (h265_header->nalus[j].type == H265::NaluType::kSps) {
+              has_h265_sps = true;
+            } else if (h265_header->nalus[j].type == H265::NaluType::kPps) {
+              has_h265_pps = true;
+            } else if (h265_header->nalus[j].type == H265::NaluType::kIdrWRadl
+                       || h265_header->nalus[j].type == H265::NaluType::kIdrNLp
+                       || h265_header->nalus[j].type == H265::NaluType::kCra) {
+              has_h265_idr = true;
+            }
+          }
+          if ((has_h265_sps && has_h265_pps) || has_h265_idr) {
+            is_h265_keyframe = true;
+          }
+        }
+
         if (tested_packets == buffer_.size())
           break;
 
@@ -325,7 +353,7 @@ std::vector<std::unique_ptr<PacketBuffer::Packet>> PacketBuffer::FindFrames(
         // the timestamp of that packet is the same as this one. This may cause
         // the PacketBuffer to hand out incomplete frames.
         // See: https://bugs.chromium.org/p/webrtc/issues/detail?id=7106
-        if (is_h264 && (buffer_[start_index] == nullptr ||
+        if ((is_h264 || is_h265) && (buffer_[start_index] == nullptr ||
                         buffer_[start_index]->timestamp != frame_timestamp)) {
           break;
         }
@@ -371,6 +399,44 @@ std::vector<std::unique_ptr<PacketBuffer::Packet>> PacketBuffer::FindFrames(
         }
       }
 
+      if (is_h265) {
+        // Warn if this is an unsafe frame.
+        if (has_h265_idr && (!has_h265_sps || !has_h265_pps)) {
+          std::stringstream ss;
+          ss << "Received H.265-IDR frame "
+             << "(SPS: " << has_h265_sps << ", PPS: " << has_h265_pps << "). ";
+          ss << "Treating as delta frame since "
+                "WebRTC-SpsPpsIdrIsH265Keyframe is always enabled.";
+          RTC_LOG(LS_WARNING) << ss.str();
+        }
+
+        // Now that we have decided whether to treat this frame as a key frame
+        // or delta frame in the frame buffer, we update the field that
+        // determines if the RtpFrameObject is a key frame or delta frame.
+        const size_t first_packet_index = start_seq_num % buffer_.size();
+        RTC_CHECK_LT(first_packet_index, buffer_.size());
+        if (is_h265_keyframe) {
+          buffer_[first_packet_index]->video_header.frame_type = VideoFrameType::kVideoFrameKey;
+        } else {
+          buffer_[first_packet_index]->video_header.frame_type = VideoFrameType::kVideoFrameDelta;
+        }
+
+        // If this is not a key frame, make sure there are no gaps in the
+        // packet sequence numbers up until this point.
+        if (!is_h265_keyframe && missing_packets_.upper_bound(start_seq_num) !=
+                                     missing_packets_.begin()) {
+          uint16_t stop_index = (index + 1) % buffer_.size();
+          while (start_index != stop_index) {
+            // FIXME: find what it does.
+            //sequence_buffer_[start_index].frame_created = false;
+            start_index = (start_index + 1) % buffer_.size();
+          }
+
+          return found_frames;
+        }
+      }
+      // (check:tnoho)
+
       const uint16_t end_seq_num = seq_num + 1;
       // Use uint16_t type to handle sequence number wrap around case.
       uint16_t num_packets = end_seq_num - start_seq_num;
diff --git a/modules/video_coding/session_info.cc b/modules/video_coding/session_info.cc
index 07b9a9d6b5..dcbf3c8175 100644
--- a/modules/video_coding/session_info.cc
+++ b/modules/video_coding/session_info.cc
@@ -147,6 +147,20 @@ std::vector<NaluInfo> VCMSessionInfo::GetNaluInfos() const {
   return nalu_infos;
 }
 
+std::vector<H265NaluInfo> VCMSessionInfo::GetH265NaluInfos() const {
+  if (packets_.empty() || packets_.front().video_header.codec != kVideoCodecH265)
+    return std::vector<H265NaluInfo>();
+  std::vector<H265NaluInfo> nalu_infos;
+  for (const VCMPacket& packet : packets_) {
+    const auto& h265 =
+        absl::get<RTPVideoHeaderH265>(packet.video_header.video_type_header);
+    for (size_t i = 0; i < h265.nalus_length; ++i) {
+      nalu_infos.push_back(h265.nalus[i]);
+    }
+  }
+  return nalu_infos;
+}
+
 void VCMSessionInfo::SetGofInfo(const GofInfoVP9& gof_info, size_t idx) {
   if (packets_.empty())
     return;
@@ -206,6 +220,9 @@ size_t VCMSessionInfo::InsertBuffer(uint8_t* frame_buffer,
   // header supplied by the H264 depacketizer.
   const size_t kH264NALHeaderLengthInBytes = 1;
   const size_t kLengthFieldLength = 2;
+  const size_t kH265NALHeaderLengthInBytes = 2;
+  const auto* h265 =
+      absl::get_if<RTPVideoHeaderH265>(&packet.video_header.video_type_header);
   const auto* h264 =
       absl::get_if<RTPVideoHeaderH264>(&packet.video_header.video_type_header);
   if (h264 && h264->packetization_type == kH264StapA) {
@@ -230,6 +247,34 @@ size_t VCMSessionInfo::InsertBuffer(uint8_t* frame_buffer,
     packet.sizeBytes = required_length;
     return packet.sizeBytes;
   }
+  else if (h265 && h265->packetization_type == kH265AP) {
+    // Similar to H264, for H265 aggregation packets, we rely on jitter buffer
+    // to remove the two length bytes between each NAL unit, and potentially add
+    // start codes.
+    size_t required_length = 0;
+    const uint8_t* nalu_ptr =
+        packet_buffer + kH265NALHeaderLengthInBytes;  // skip payloadhdr
+    while (nalu_ptr < packet_buffer + packet.sizeBytes) {
+      size_t length = BufferToUWord16(nalu_ptr);
+      required_length +=
+          length + (packet.insertStartCode ? kH265StartCodeLengthBytes : 0);
+      nalu_ptr += kLengthFieldLength + length;
+    }
+    ShiftSubsequentPackets(packet_it, required_length);
+    nalu_ptr = packet_buffer + kH265NALHeaderLengthInBytes;
+    uint8_t* frame_buffer_ptr = frame_buffer + offset;
+    while (nalu_ptr < packet_buffer + packet.sizeBytes) {
+      size_t length = BufferToUWord16(nalu_ptr);
+      nalu_ptr += kLengthFieldLength;
+      // since H265 shares the same start code as H264, use the same Insert
+      // function to handle start code.
+      frame_buffer_ptr += Insert(nalu_ptr, length, packet.insertStartCode,
+                                 const_cast<uint8_t*>(frame_buffer_ptr));
+      nalu_ptr += length;
+    }
+    packet.sizeBytes = required_length;
+    return packet.sizeBytes;
+  }
   ShiftSubsequentPackets(
       packet_it, packet.sizeBytes +
                      (packet.insertStartCode ? kH264StartCodeLengthBytes : 0));
@@ -456,6 +501,18 @@ int VCMSessionInfo::InsertPacket(const VCMPacket& packet,
          IsNewerSequenceNumber(packet.seqNum, last_packet_seq_num_))) {
       last_packet_seq_num_ = packet.seqNum;
     }
+  } else if (packet.codec() == kVideoCodecH265) {
+    frame_type_ = packet.video_header.frame_type;
+    if (packet.is_first_packet_in_frame() &&
+        (first_packet_seq_num_ == -1 ||
+         IsNewerSequenceNumber(first_packet_seq_num_, packet.seqNum))) {
+      first_packet_seq_num_ = packet.seqNum;
+    }
+    if (packet.markerBit &&
+        (last_packet_seq_num_ == -1 ||
+         IsNewerSequenceNumber(packet.seqNum, last_packet_seq_num_))) {
+      last_packet_seq_num_ = packet.seqNum;
+    }
   } else {
     // Only insert media packets between first and last packets (when
     // available).
diff --git a/modules/video_coding/session_info.h b/modules/video_coding/session_info.h
index 06a348ef72..5ad8a6e91d 100644
--- a/modules/video_coding/session_info.h
+++ b/modules/video_coding/session_info.h
@@ -65,6 +65,7 @@ class VCMSessionInfo {
   int Tl0PicId() const;
 
   std::vector<NaluInfo> GetNaluInfos() const;
+  std::vector<H265NaluInfo> GetH265NaluInfos() const;
 
   void SetGofInfo(const GofInfoVP9& gof_info, size_t idx);
 
diff --git a/rtc_base/experiments/min_video_bitrate_experiment.cc b/rtc_base/experiments/min_video_bitrate_experiment.cc
index 11450d0849..bc86d35965 100644
--- a/rtc_base/experiments/min_video_bitrate_experiment.cc
+++ b/rtc_base/experiments/min_video_bitrate_experiment.cc
@@ -100,6 +100,7 @@ absl::optional<DataRate> GetExperimentalMinVideoBitrate(VideoCodecType type) {
         return min_bitrate_av1.GetOptional();
       case kVideoCodecH264:
         return min_bitrate_h264.GetOptional();
+      case kVideoCodecH265:
       case kVideoCodecGeneric:
       case kVideoCodecMultiplex:
         return absl::nullopt;
diff --git a/video/rtp_video_stream_receiver.cc b/video/rtp_video_stream_receiver.cc
index 1b8828be2c..894e9f6eae 100644
--- a/video/rtp_video_stream_receiver.cc
+++ b/video/rtp_video_stream_receiver.cc
@@ -628,7 +628,22 @@ void RtpVideoStreamReceiver::OnReceivedPayloadData(
         packet->video_payload = std::move(fixed.bitstream);
         break;
     }
-
+  } else if (packet->codec() == kVideoCodecH265) {
+    video_coding::H265VpsSpsPpsTracker::FixedBitstream fixed =
+        h265_tracker_.CopyAndFixBitstream(
+            rtc::MakeArrayView(codec_payload.cdata(), codec_payload.size()),
+            &packet->video_header);
+    switch (fixed.action) {
+      case video_coding::H265VpsSpsPpsTracker::kRequestKeyframe:
+        rtcp_feedback_buffer_.RequestKeyFrame();
+        rtcp_feedback_buffer_.SendBufferedRtcpFeedback();
+        ABSL_FALLTHROUGH_INTENDED;
+      case video_coding::H265VpsSpsPpsTracker::kDrop:
+        return;
+      case video_coding::H265VpsSpsPpsTracker::kInsert:
+        packet->video_payload = std::move(fixed.bitstream);
+        break;
+    }
   } else {
     packet->video_payload = std::move(codec_payload);
   }
diff --git a/video/rtp_video_stream_receiver.h b/video/rtp_video_stream_receiver.h
index 40958c48ec..2bc7edc2cd 100644
--- a/video/rtp_video_stream_receiver.h
+++ b/video/rtp_video_stream_receiver.h
@@ -37,6 +37,7 @@
 #include "modules/rtp_rtcp/source/rtp_video_header.h"
 #include "modules/rtp_rtcp/source/video_rtp_depacketizer.h"
 #include "modules/video_coding/h264_sps_pps_tracker.h"
+#include "modules/video_coding/h265_vps_sps_pps_tracker.h"
 #include "modules/video_coding/loss_notification_controller.h"
 #include "modules/video_coding/packet_buffer.h"
 #include "modules/video_coding/rtp_frame_reference_finder.h"
@@ -362,6 +363,7 @@ class RtpVideoStreamReceiver : public LossNotificationSender,
   std::map<int64_t, uint16_t> last_seq_num_for_pic_id_
       RTC_GUARDED_BY(last_seq_num_mutex_);
   video_coding::H264SpsPpsTracker tracker_;
+  video_coding::H265VpsSpsPpsTracker h265_tracker_;
 
   // Maps payload id to the depacketizer.
   std::map<uint8_t, std::unique_ptr<VideoRtpDepacketizer>> payload_type_map_;
diff --git a/video/rtp_video_stream_receiver2.cc b/video/rtp_video_stream_receiver2.cc
index f3345597ea..6336642682 100644
--- a/video/rtp_video_stream_receiver2.cc
+++ b/video/rtp_video_stream_receiver2.cc
@@ -597,6 +597,23 @@ void RtpVideoStreamReceiver2::OnReceivedPayloadData(
         break;
     }
 
+  } else if (packet->codec() == kVideoCodecH265) {
+    video_coding::H265VpsSpsPpsTracker::FixedBitstream fixed =
+        h265_tracker_.CopyAndFixBitstream(
+            rtc::MakeArrayView(codec_payload.cdata(), codec_payload.size()),
+            &packet->video_header);
+    switch (fixed.action) {
+      case video_coding::H265VpsSpsPpsTracker::kRequestKeyframe:
+        rtcp_feedback_buffer_.RequestKeyFrame();
+        rtcp_feedback_buffer_.SendBufferedRtcpFeedback();
+        ABSL_FALLTHROUGH_INTENDED;
+      case video_coding::H265VpsSpsPpsTracker::kDrop:
+        return;
+      case video_coding::H265VpsSpsPpsTracker::kInsert:
+        packet->video_payload = std::move(fixed.bitstream);
+        break;
+    }
+
   } else {
     packet->video_payload = std::move(codec_payload);
   }
diff --git a/video/rtp_video_stream_receiver2.h b/video/rtp_video_stream_receiver2.h
index 40e7ef6f1b..a14045f38b 100644
--- a/video/rtp_video_stream_receiver2.h
+++ b/video/rtp_video_stream_receiver2.h
@@ -35,6 +35,7 @@
 #include "modules/rtp_rtcp/source/rtp_video_header.h"
 #include "modules/rtp_rtcp/source/video_rtp_depacketizer.h"
 #include "modules/video_coding/h264_sps_pps_tracker.h"
+#include "modules/video_coding/h265_vps_sps_pps_tracker.h"
 #include "modules/video_coding/loss_notification_controller.h"
 #include "modules/video_coding/packet_buffer.h"
 #include "modules/video_coding/rtp_frame_reference_finder.h"
@@ -325,6 +326,7 @@ class RtpVideoStreamReceiver2 : public LossNotificationSender,
   std::map<int64_t, uint16_t> last_seq_num_for_pic_id_
       RTC_GUARDED_BY(worker_task_checker_);
   video_coding::H264SpsPpsTracker tracker_ RTC_GUARDED_BY(worker_task_checker_);
+  video_coding::H265VpsSpsPpsTracker h265_tracker_ RTC_GUARDED_BY(worker_task_checker_);
 
   // Maps payload id to the depacketizer.
   std::map<uint8_t, std::unique_ptr<VideoRtpDepacketizer>> payload_type_map_
diff --git a/video/send_statistics_proxy.cc b/video/send_statistics_proxy.cc
index ee32fd91c1..0b46f9f744 100644
--- a/video/send_statistics_proxy.cc
+++ b/video/send_statistics_proxy.cc
@@ -47,6 +47,7 @@ enum HistogramCodecType {
   kVideoVp8 = 1,
   kVideoVp9 = 2,
   kVideoH264 = 3,
+  kVideoH265 = 4,
   kVideoMax = 64,
 };
 
@@ -74,6 +75,8 @@ HistogramCodecType PayloadNameToHistogramCodecType(
       return kVideoVp9;
     case kVideoCodecH264:
       return kVideoH264;
+    case kVideoCodecH265:
+      return kVideoH265;
     default:
       return kVideoUnknown;
   }
diff --git a/video/video_receive_stream.cc b/video/video_receive_stream.cc
index 02eb9034fc..3755b6afea 100644
--- a/video/video_receive_stream.cc
+++ b/video/video_receive_stream.cc
@@ -125,6 +125,8 @@ VideoCodec CreateDecoderVideoCodec(const VideoReceiveStream::Decoder& decoder) {
     *(codec.VP9()) = VideoEncoder::GetDefaultVp9Settings();
   } else if (codec.codecType == kVideoCodecH264) {
     *(codec.H264()) = VideoEncoder::GetDefaultH264Settings();
+  } else if (codec.codecType == kVideoCodecH265) {
+    *(codec.H265()) = VideoEncoder::GetDefaultH265Settings();
   } else if (codec.codecType == kVideoCodecMultiplex) {
     VideoReceiveStream::Decoder associated_decoder = decoder;
     associated_decoder.video_format =
diff --git a/video/video_stream_encoder.cc b/video/video_stream_encoder.cc
index f229a6097e..44512af673 100644
--- a/video/video_stream_encoder.cc
+++ b/video/video_stream_encoder.cc
@@ -111,6 +111,12 @@ bool RequiresEncoderReset(const VideoCodec& prev_send_codec,
       }
       break;
 
+    case kVideoCodecH265:
+      if (new_send_codec.H265() != prev_send_codec.H265()) {
+        return true;
+      }
+      break;
+
     default:
       break;
   }
@@ -1594,6 +1600,7 @@ EncodedImageCallback::Result VideoStreamEncoder::OnEncodedImage(
   if (codec_specific_info &&
       (codec_specific_info->codecType == kVideoCodecVP8 ||
        codec_specific_info->codecType == kVideoCodecH264 ||
+       codec_specific_info->codecType == kVideoCodecH265 ||
        codec_specific_info->codecType == kVideoCodecGeneric)) {
     simulcast_id = encoded_image.SpatialIndex().value_or(0);
   }
